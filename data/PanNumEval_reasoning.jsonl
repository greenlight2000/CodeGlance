{"ID":"0","code":"import pandas as pd\nimport numpy as np\n\ndef f(df):\n    return  df.where(pd.notnull(df), None)\n","test":"df = pd.DataFrame({'col1': [1, np.nan, 3],'col2': ['a', 'b', np.nan]})\nassert f(df).iloc[2, 1] == <ground_truth>","result":"None","code_lines":2,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"1","code":"import pandas as pd\nimport numpy as np\n\ndef f():\n    numpy_array = np.zeros((3, 4))\n    df = pd.DataFrame(numpy_array)\n    return df.head(2)\n","test":"assert f().iloc[1, 2] == <ground_truth>","result":"0","code_lines":4,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"2","code":"import pandas as pd\nimport numpy as np\n\n\ndef f(df, threshold_sales, year_start, year_end):\n    filtered_sales_data = df.loc[\n        (df['Sales'] >= threshold_sales) & (df['Year'].isin(np.arange(year_start, year_end + 1)))]\n    return filtered_sales_data\n","test":"df = pd.DataFrame({'Product': ['A', 'B', 'C', 'D'],'Sales': [100, 250, 300, 150],'Year': [2019, 2020, 2021, 2022]})\nthreshold_sales = 200\nyear_start = 2020\nyear_end = 2021\nassert f(df, threshold_sales, year_start, year_end).iloc[0]['Product'] == <ground_truth>","result":"'B'","code_lines":4,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"3","code":"import pandas as pd\nimport numpy as np\n\ndef f(array1, array2, df):\n    concatenated_array = np.concatenate((array1, array2), axis=0)\n    concatenated_df = pd.DataFrame(concatenated_array, columns=df.columns)\n    deduplicated_df = concatenated_df.drop_duplicates()\n    return deduplicated_df\n","test":"array1 = np.array([[1, 'A'], [2, 'B']])\narray2 = np.array([[2, 'B'], [3, 'C']])\ndf = pd.DataFrame(columns=['ID', 'Label'])\nassert f(array1, array2, df).iloc[1]['Label'] == <ground_truth>","result":"'B'","code_lines":5,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"4","code":"import pandas as pd\nimport numpy as np\n\ndef f(df1, df2, columns):\n    mean_df1 = pd.Series(df1.mean())\n    mean_df2 = pd.Series(df2.mean())\n\n    mean_concatenated = pd.concat([mean_df1, mean_df2], axis=1)\n    mean_concatenated.columns = columns\n    return mean_concatenated\n","test":"df1 = pd.DataFrame({'A': [1, 2, 3],'B': [4, 5, 6]})\ndf2 = pd.DataFrame({'A': [10, 20, 30],'B': [40, 50, 60]})\ncolumns = ['mean_df1', 'mean_df2']\nassert f(df1, df2, columns).loc['A', 'mean_df2'] == <ground_truth>","result":"20","code_lines":6,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"5","code":"import pandas as pd\nimport numpy as np\n\ndef f(matrix1, matrix2, key_column, df):\n    result_matrix = np.dot(matrix1, matrix2)\n    result_df = pd.DataFrame(result_matrix, columns=df.columns)\n    merged_df = pd.merge(df, result_df, on=key_column)\n    return merged_df\n","test":"df = pd.DataFrame({'id': [1, 2],'feature1': [10, 20],'feature2': [30, 40]})\nmatrix1 = np.array([[1, 0], [0, 1]])\nmatrix2 = np.array([[5, 6], [7, 8]])\nassert f(matrix1, matrix2, 'id', df).loc[0, 'feature2_y'] == <ground_truth>","result":"6","code_lines":5,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"6","code":"import pandas as pd\nimport numpy as np\n\ndef f(df):\n    column_sums = df.sum(axis=0)\n    sum_column_names = [f'{col}_sum' for col in df.columns]\n    df_sum = pd.DataFrame([column_sums.tolist()], columns=sum_column_names)\n    return df_sum\n","test":"df = pd.DataFrame({'A': [1, 2, 3],'B': [4, 5, 6]})\nassert f(df).at[0, 'B_sum'] == <ground_truth>","result":"15","code_lines":5,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"7","code":"import pandas as pd\nimport numpy as np\n\ndef f(df):\n    row_sums = df.apply(np.sum, axis=1)\n    df['Total'] = row_sums\n\n    renamed_df = df.rename(columns=lambda col: 'Column_' + col)\n    return renamed_df\n","test":"df = pd.DataFrame({'A': [1, 2],'B': [3, 4]})\nassert f(df).at[1, 'Column_Total'] == <ground_truth>","result":"6","code_lines":5,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"8","code":"import pandas as pd\nimport numpy as np\n\ndef f(df):\n    split_dfs = np.split(df, [df.index[df['Value'].isna()].tolist()[0]])\n    cleaned_dfs = [split.dropna() for split in split_dfs]\n    return cleaned_dfs[0], cleaned_dfs[1]\n","test":"df = pd.DataFrame({'ID': [1, 2, 3, 4, 5],'Value': [10.0, 20.0, np.nan, 40.0, 50.0]})\npart1, part2 = f(df)\nassert part2.iloc[0]['Value'] == <ground_truth>","result":"40","code_lines":4,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"9","code":"import pandas as pd\nimport numpy as np\n\ndef f(df, tile_rows, fill_value):\n    tiled_rows = np.tile(df.values, (tile_rows, 1))\n    tiled_df = pd.DataFrame(tiled_rows, columns=df.columns)\n    filled_df = tiled_df.fillna(fill_value)\n    return filled_df\n","test":"df = pd.DataFrame({'A': [1, np.nan],'B': [np.nan, 4]})\ntile_rows = 3\nfill_value = 0\nassert f(df, tile_rows, fill_value).shape[0] == <ground_truth>","result":"6","code_lines":5,"cyclomatic_complexity":1,"common_api_count":6}
{"ID":"10","code":"import pandas as pd\nimport numpy as np\n\ndef f(df, column_name, repeat_times):\n    repeated_values = np.repeat(df[column_name], repeat_times)\n    repeated_df = df.loc[repeated_values.index].copy()\n    repeated_df[column_name] = repeated_values\n    sorted_df = repeated_df.sort_values(by=column_name)\n    return sorted_df\n","test":"df = pd.DataFrame({'ID': [1, 2],'Score': [30, 10]})\nassert f(df, 'Score', 2).iloc[0]['Score'] == <ground_truth>","result":"10","code_lines":6,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"11","code":"import pandas as pd\nimport numpy as np\n\ndef f(array, df):\n    transposed_array = array.T\n    stacked_df = pd.concat([df, pd.DataFrame(transposed_array, columns=df.columns)])\n    return stacked_df\n","test":"df = pd.DataFrame({'A': [1, 2],'B': [3, 4]})\narray = np.array([[5, 6], [7, 8]])\nassert f(array, df).iloc[2]['A'] == <ground_truth>","result":"5","code_lines":4,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"12","code":"import pandas as pd\nimport numpy as np\n\ndef f(df):\n    year_sales_stats = df.groupby('Year')['Sales'].agg([np.mean, np.median]).reset_index()\n    year_sales_stats.columns = ['Year', 'Mean_Sales', 'Median_Sales']\n    return year_sales_stats\n","test":"df = pd.DataFrame({'Year': [2020, 2020, 2021, 2021, 2021],'Sales': [100, 200, 300, 400, 500]})\nassert f(df).loc[f(df)['Year'] == 2020, 'Mean_Sales'].values[0] == <ground_truth>","result":"150","code_lines":4,"cyclomatic_complexity":1,"common_api_count":1}
{"ID":"13","code":"import pandas as pd\nimport numpy as np\n\n\ndef f(matrix, df):\n    eigenvalues, _ = np.linalg.eig(matrix)\n    num_eigenvalues = len(eigenvalues)\n\n    if num_eigenvalues == 0:\n        return pd.DataFrame()\n    top_eigenvalue_indices = np.argsort(np.abs(eigenvalues))[-num_eigenvalues:]\n    selected_columns = df.iloc[:, top_eigenvalue_indices]\n    return selected_columns\n","test":"matrix = np.array([[2, 0],[0, 3]])\ndf = pd.DataFrame({'A': [1, 2],'B': [3, 4]})\nassert f(matrix, df).iloc[1, 1] == <ground_truth>","result":"4","code_lines":8,"cyclomatic_complexity":2,"common_api_count":7}
{"ID":"14","code":"import pandas as pd\nimport numpy as np\n\ndef f(df):\n    reshaped_array = np.reshape(df.values, (3, 4))\n    reshaped_df = pd.DataFrame(reshaped_array, columns=['A', 'B', 'C', 'D'])\n    first_two_rows = reshaped_df.head(2)\n    return first_two_rows\n","test":"df = pd.DataFrame(np.arange(1, 13).reshape(4, 3))\nassert f(df).iloc[1, 2] == <ground_truth>","result":"7","code_lines":5,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"15","code":"import pandas as pd\nimport numpy as np\n\ndef f(array1, array2, df, sort_column):\n    concatenated_array = np.concatenate((array1, array2), axis=0)\n    concatenated_df = pd.DataFrame(concatenated_array, columns=df.columns)\n    sorted_df = concatenated_df.sort_values(by=sort_column)\n    return sorted_df\n","test":"array1 = np.array([[2, 'B'], [1, 'A']])\narray2 = np.array([[3, 'C']])\ndf = pd.DataFrame(columns=['ID', 'Label'])\nassert f(array1, array2, df, 'ID').iloc[0]['Label'] == <ground_truth>","result":"'A'","code_lines":5,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"16","code":"import pandas as pd\nimport numpy as np\n\ndef f(array1, array2, column_name, df):\n    np.copyto(df[column_name].values, np.concatenate((array1, array2)))\n    sorted_df = df.sort_values(by=column_name)\n\n    return sorted_df\n","test":"df = pd.DataFrame({'ID': [0, 0, 0],'Label': ['A', 'B', 'C']})\narray1 = np.array([10])\narray2 = np.array([30, 20])\nassert f(array1, array2, 'ID', df).iloc[2]['ID'] == <ground_truth>","result":"30","code_lines":4,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"17","code":"import pandas as pd\nimport numpy as np\n\ndef f(data_list):\n    concatenated_df = pd.concat([pd.DataFrame(data) for data in data_list], ignore_index=True)\n    df_list = np.array_split(concatenated_df, 2)\n    return df_list[0], df_list[1]\n","test":"data_list = [{'A': [1], 'B': [2]},{'A': [3], 'B': [4]},{'A': [5], 'B': [6]},{'A': [7], 'B': [8]}]\npart1, part2 = f(data_list)\nassert part2.iloc[1]['A'] == <ground_truth>","result":"7","code_lines":4,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"18","code":"import pandas as pd\nimport numpy as np\n\n\ndef f(df, array, value_to_replace, new_value):\n    updated_array = np.where(array == value_to_replace, new_value, array)\n    df['Value'] = updated_array\n\n    matching_indices = df.loc[df['Value'] == new_value, 'ID'].tolist()\n\n    return matching_indices\n","test":"df = pd.DataFrame({'ID': [101, 102, 103, 104],'Value': [0, 0, 0, 0]})\narray = np.array([1, 2, 1, 3])\nassert f(df, array, 1, 99)[0] == <ground_truth>","result":"101","code_lines":5,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"19","code":"import pandas as pd\nimport numpy as np\n\ndef f(df, shift_amount, threshold_value):\n    rolled_df = pd.DataFrame(np.roll(df.values, shift_amount, axis=1), columns=df.columns)\n    filtered_df = rolled_df.loc[(rolled_df >= threshold_value).all(axis=1)]\n    return filtered_df\n","test":"df = pd.DataFrame({'A': [1, 5, 9],'B': [2, 6, 10],'C': [3, 7, 11]})\nassert f(df, shift_amount=1, threshold_value=6).iloc[0, 0] == <ground_truth>","result":"11","code_lines":4,"cyclomatic_complexity":1,"common_api_count":1}
{"ID":"20","code":"import pandas as pd\nimport numpy as np\n\ndef f(df, start_year, end_year):\n    filtered_df = df.loc[(df['Year'].isin(np.arange(start_year, end_year + 1))) & (df['Temperature'] > 20)]\n\n    return filtered_df\n","test":"df = pd.DataFrame({'Year': [2018, 2019, 2020, 2021, 2022],'Temperature': [18, 22, 25, 19, 30]})\nassert f(df, 2019, 2021).shape[0] == <ground_truth>","result":"2","code_lines":3,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"21","code":"import pandas as pd\nimport numpy as np\n\ndef f(array1, array2, df):\n    concatenated_array = np.concatenate((array1, array2), axis=0)\n    concatenated_df = pd.DataFrame(concatenated_array, columns=df.columns)\n    deduplicated_df = concatenated_df.drop_duplicates()\n    return deduplicated_df\n","test":"array1 = np.array([[1, 'A'], [2, 'B']])\narray2 = np.array([[2, 'B'], [3, 'C']])\ndf = pd.DataFrame(columns=['ID', 'Label'])\nassert f(array1, array2, df).iloc[2]['Label'] == <ground_truth>","result":"'C'","code_lines":5,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"22","code":"import pandas as pd\nimport numpy as np\n\ndef f(df):\n    nonzero_counts = df.apply(np.count_nonzero)\n    return nonzero_counts\n","test":"df = pd.DataFrame({'A': [0, 1, 2, 0],'B': [0, 0, 0, 0],'C': [3, 0, 4, 5]})\nassert f(df)['A'] == <ground_truth>","result":"2","code_lines":3,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"23","code":"import pandas as pd\nimport numpy as np\n\ndef f(array, df):\n    unique_integers = np.unique(array)\n    integer_label_mapping = df.set_index('Integer')['Label'].to_dict()\n    mapped_labels = [integer_label_mapping[i] for i in unique_integers]\n    return mapped_labels\n","test":"array = np.array([2, 3, 2, 1, 3, 4])\ndf = pd.DataFrame({'Integer': [1, 2, 3, 4],'Label': ['one', 'two', 'three', 'four']})\nassert f(array, df)[0] == <ground_truth>","result":"'one'","code_lines":5,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"24","code":"import pandas as pd\nimport numpy as np\n\ndef f(names_array, df):\n    first_names, last_names = np.vectorize(lambda x: x.split()[0])(names_array), np.vectorize(lambda x: x.split()[-1])(names_array)\n    new_df = pd.DataFrame({'First Name': first_names, 'Last Name': last_names})\n    return new_df\n","test":"names_array = np.array([\"John Smith\",\"Alice Johnson\",\"Bob A. Lee\"])\nassert f(names_array, None).iloc[2]['First Name'] == <ground_truth>","result":"'Bob'","code_lines":4,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"25","code":"import pandas as pd\nimport numpy as np\n\ndef f(data, fill_value):\n    filled_data = data.fillna(fill_value)\n    cumulative_sum_data = filled_data.cumsum()\n    deduplicated_data = cumulative_sum_data.drop_duplicates()\n    return deduplicated_data\n","test":"data = pd.DataFrame({'A': [1, np.nan, 2, 0],'B': [0, 1, 1, np.nan]})\nassert f(data, fill_value = 0).iloc[1]['A'] == <ground_truth>","result":"3","code_lines":5,"cyclomatic_complexity":1,"common_api_count":1}
{"ID":"26","code":"import pandas as pd\nimport numpy as np\n\ndef f(data1, data2):\n    filled_data1 = data1.fillna(0)\n    filled_data2 = data2.fillna(0)\n    cumulative_sum_data1 = filled_data1.cumsum()\n    cumulative_sum_data2 = filled_data2.cumsum()\n    concatenated_data = pd.concat([cumulative_sum_data1, cumulative_sum_data2], axis=0)\n    deduplicated_data = concatenated_data.drop_duplicates()\n    return deduplicated_data\n","test":"data1 = pd.DataFrame({'A': [1, np.nan],'B': [0, 1]})\ndata2 = pd.DataFrame({'A': [1, 1],'B': [0, 1]})\nassert f(data1, data2).iloc[2]['A'] == <ground_truth>","result":"2","code_lines":8,"cyclomatic_complexity":1,"common_api_count":6}
{"ID":"27","code":"import pandas as pd\nimport numpy as np\n\ndef f(data, category_col, value_col):\n    grouped_data = data.groupby(category_col).mean()\n    category_names = grouped_data.index.values\n    mean_values = np.add(grouped_data[value_col], 10)\n    result_array = np.array([category_names, mean_values])\n    return result_array\n","test":"data = pd.DataFrame({'Type': ['A', 'A', 'B', 'B', 'C'],'Score': [80, 90, 70, 60, 75]})\nassert f(data, 'Type', 'Score')[1][0] == <ground_truth>","result":"95","code_lines":6,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"28","code":"import pandas as pd\nimport numpy as np\n\ndef f(data, column_name, start_value, end_value):\n    queried_data = data.query(f'{start_value} <= {column_name} <= {end_value}')\n    column_std = np.std(queried_data[column_name])\n    result_shape = queried_data.shape\n    return column_std, result_shape\n","test":"data = pd.DataFrame({'Score': [50, 60, 70, 80, 90, 100],'Name': ['A', 'B', 'C', 'D', 'E', 'F']})\nstd_val, shape_val = f(data, 'Score', 60, 90)\nassert shape_val == <ground_truth>","result":"(4, 2)","code_lines":5,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"29","code":"import pandas as pd\nimport numpy as np\n\ndef f(data, column_name, start_index, end_index, multiplier):\n    filtered_data = data.loc[start_index:end_index]\n    filtered_data[column_name] = np.multiply(filtered_data[column_name], multiplier)\n    modified_data = filtered_data.drop_duplicates()\n    return modified_data\n","test":"data = pd.DataFrame({'A': [1, 2, 2, 3, 4],'B': [10, 20, 20, 30, 40]}, index=[0, 1, 2, 3, 4])\nassert f(data, 'B', 1, 3, 2).loc[3, 'B'] == <ground_truth>","result":"60","code_lines":5,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"30","code":"import numpy as np\nimport pandas as pd\n\ndef f(arr):\n    unique_values = np.unique(arr)\n    cumulative_sum = np.cumsum(unique_values)\n    df = pd.DataFrame(arr, columns=['Value'])\n    grouped = df.groupby('Value').size().reset_index(name='Occurrences')\n    grouped_sum = grouped.groupby('Value')['Occurrences'].sum()\n    return cumulative_sum, grouped_sum\n","test":"arr = np.array([1, 2, 2, 3, 3, 3, 5])\ncumulative_sum, grouped_sum = f(arr)\nassert grouped_sum[3] == <ground_truth>","result":"3","code_lines":7,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"31","code":"import numpy as np\nimport pandas as pd\n\ndef f():\n    original_array = np.arange(1, 21)\n    reshaped_array = np.reshape(original_array, (4, 5))\n    std_value = np.std(reshaped_array)\n    df = pd.DataFrame(reshaped_array, columns=['Col1', 'Col2', 'Col3', 'Col4', 'Col5'])\n    filtered_df = df.query('Col1 > 2')\n    hist, bin_edges = np.histogram(filtered_df['Col2'], bins=5)\n    return std_value, filtered_df, hist\n","test":"std_value, filtered_df, hist = f()\nassert filtered_df.iloc[0]['Col1'] == <ground_truth>","result":"6","code_lines":8,"cyclomatic_complexity":1,"common_api_count":6}
{"ID":"32","code":"import pandas as pd\nimport numpy as np\n\ndef f():\n    df1 = pd.DataFrame({'Name': ['A', 'B', 'C', 'A', 'B'],\n                        'Value': [1, 2, 3, 4, 5]})\n\n    df2 = pd.DataFrame({'Name': ['C', 'D', 'D', 'E', 'E'],\n                        'Value': [6, 7, 8, 9, 10]})\n\n    stacked_df = pd.DataFrame(np.row_stack([df1.values, df2.values]), columns=['Name', 'Value'])\n    deduplicated_df = stacked_df.drop_duplicates(subset=['Name'])\n    pivot_table = deduplicated_df.pivot_table(index='Name', values='Value', aggfunc='sum')\n    return pivot_table\n","test":"pivot_table = f()\nassert pivot.loc['D', 'Value'] == <ground_truth>","result":"7","code_lines":9,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"33","code":"import numpy as np\nimport pandas as pd\n\ndef f(sales_data):\n    grouped_data = sales_data.groupby('Region')['Sales'].sum()\n    max_sales = np.max(grouped_data)\n    min_sales = np.min(grouped_data)\n    return max_sales, min_sales\n","test":"sales_data = pd.DataFrame({'Region': ['North', 'South', 'North', 'East', 'West', 'South'],'Sales': [100, 200, 150, 50, 120, 180]})\nmax_sales, min_sales = f(df)\nassert max_sales == <ground_truth>","result":"380","code_lines":5,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"34","code":"import numpy as np\nimport pandas as pd\n\ndef f():\n    values = np.linspace(1, 99, 50, dtype='int32')\n    df = pd.DataFrame({'Value': values})\n    filtered_df = df.query('sqrt(Value) > 5')\n    filtered_shape = filtered_df.shape\n    return filtered_shape\n","test":"assert f()[0] == <ground_truth>","result":"37","code_lines":6,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"35","code":"import numpy as np\nimport pandas as pd\n\ndef f(scores):\n    filtered_scores = scores.loc[(scores['Score'] >= 80) & (scores['Subject'] == 'Math')]\n    sorted_scores = filtered_scores.sort_values(by='Score', ascending=False)\n    highest_score = np.max(sorted_scores['Score'])\n    return highest_score\n","test":"scores = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],'Subject': ['Math', 'Math', 'Science', 'Math', 'Math'],'Score': [85, 78, 91, 92, 80]})\nassert f(scores) == <ground_truth>","result":"92","code_lines":5,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"36","code":"import numpy as np\nimport pandas as pd\n\ndef f(student_scores):\n    sorted_scores = student_scores.sort_values(by='Score')\n    index_to_find = np.searchsorted(sorted_scores['Score'], 85, side='right')\n    row_with_high_score = sorted_scores.loc[index_to_find]\n    return row_with_high_score\n","test":"student_scores = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie', 'David'],'Score': [83, 85, 86, 90]})\nssert f(student_scores)['Score'] == <ground_truth>","result":"86","code_lines":5,"cyclomatic_complexity":1,"common_api_count":1}
{"ID":"37","code":"import numpy as np\nimport pandas as pd\n\ndef f(data):\n    transposed_data = np.transpose(data)\n    row_means = transposed_data.apply(pd.Series.dropna, axis=1).mean()\n    columns = data.columns\n    sorted_rows = transposed_data.loc[[columns[index] for index in row_means.sort_values(ascending=False).index]]\n    return sorted_rows\n","test":"data = pd.DataFrame({'A': [1, 2, 3],'B': [4, 5, 6],'C': [7, 8, 9]})\nassert list(f(data).index)[0] == <ground_truth>","result":"'C'","code_lines":6,"cyclomatic_complexity":1,"common_api_count":7}
{"ID":"38","code":"import numpy as np\nimport pandas as pd\n\ndef f(sales_data):\n    filtered_data = sales_data.loc[(sales_data['Region'] == 'North') & (sales_data['Sales'] > 100)]\n    filtered_data['LogSales'] = np.log(filtered_data['Sales'])\n    product_summary = filtered_data.groupby('Product')['LogSales'].describe()\n    return product_summary\n","test":"sales_data = pd.DataFrame({'Region': ['North', 'North', 'South', 'North', 'North'],'Product': ['A', 'B', 'A', 'A', 'B'],'Sales': [120, 130, 90, 150, 80]})\nassert f(sales_data).loc['A', 'count'] == <ground_truth>","result":"2","code_lines":5,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"39","code":"import pandas as pd\nimport numpy as np\n\ndef f():\n    numpy_array = np.linspace(0, 100, 20, dtype='int32').reshape(4, 5)\n    df = pd.DataFrame(numpy_array, columns=['A', 'B', 'C', 'D', 'E'])\n    return df.tail(3)\n","test":"assert f().iloc[-1, -1] == <ground_truth>","result":"100","code_lines":4,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"40","code":"import pandas as pd\nimport numpy as np\n\ndef f(df):\n    hist, bins = np.histogram(df['age'], bins=3)\n    df['age_group'] = pd.cut(df['age'], bins=bins, labels=['Group 1', 'Group 2', 'Group 3'])\n\n    pivot_table = df.pivot_table(values='height', index='age_group', aggfunc='mean')\n    mean_height = df['height'].mean()\n    std_dev_height = df['height'].std()\n    filtered_pivot_table = pivot_table.query('height > @mean_height + @std_dev_height')\n    return filtered_pivot_table\n","test":"df = pd.DataFrame({'age':    [12, 15, 18, 22, 26, 30, 35, 40, 45],'height': [140, 150, 155, 160, 165, 170, 175, 180, 190]})\nassert f(df).shape[0] == <ground_truth>","result":"1","code_lines":8,"cyclomatic_complexity":1,"common_api_count":5}
{"ID":"41","code":"import pandas as pd\nimport numpy as np\n\n\ndef f(df):\n    df['profit'] = df['sales'] - df['expenses']\n    profit_stats = df.groupby('category').agg({'profit': ['mean', 'count']})\n    profit_stats['log_avg_profit'] = np.log(profit_stats[('profit', 'mean')])\n\n    sorted_categories = profit_stats.sort_values(by=('log_avg_profit'), ascending=False)\n    return sorted_categories\n","test":"df = pd.DataFrame({'category': ['A',  'B', 'B', 'C'],'sales':    [100,  200, 250, 50],'expenses': [ 60,  220, 240, 60]})\nassert f(df).index[0] == <ground_truth>","result":"'A'","code_lines":6,"cyclomatic_complexity":1,"common_api_count":3}
{"ID":"42","code":"import pandas as pd\nimport numpy as np\n\n\ndef f():\n    num_array = np.arange(1, 21)\n    reshaped_array = np.reshape(num_array, (4, 5))\n\n    df = pd.DataFrame(reshaped_array, columns=['C1', 'C2', 'C3', 'C4', 'C5'])\n\n    row_sum = df.apply(np.sum, axis=1)\n    col_product = df.apply(np.prod, axis=0)\n\n    return df.shape, df.tail(3), row_sum, col_product\n","test":"shape, tail_df, row_sum, col_product = f()\nassert tail_df.iloc[0][0] == <ground_truth>","result":"6","code_lines":7,"cyclomatic_complexity":1,"common_api_count":8}
{"ID":"43","code":"import pandas as pd\nimport numpy as np\n\n\ndef f():\n    a = np.arange(1, 13)\n    reshaped_a = np.reshape(a, (3, 4))\n    reshaped_b = np.reshape(a, (4, 3))\n\n    df_a = pd.DataFrame(reshaped_a, columns=['A1', 'A2', 'A3', 'A4'])\n    df_b = pd.DataFrame(reshaped_b, columns=['B1', 'B2', 'B3'])\n\n    dot_product = np.dot(df_a, df_b)\n\n    return dot_product\n","test":"assert f().shape[0] == <ground_truth>","result":"3","code_lines":8,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"44","code":"import numpy as np\nimport pandas as pd\n\ndef f(start_num, end_num):\n    num_array = np.arange(start_num, end_num)\n    reshaped_array = np.reshape(num_array, (3, 3))\n\n    df = pd.DataFrame(reshaped_array, index=['C', 'B', 'A'], columns=['X', 'Y', 'Z'])\n\n    sorted_df = df.sort_index(ascending=False)\n\n    A = sorted_df.values\n    B = np.array([10, 20, 30])\n\n    solution = np.linalg.solve(A, B)\n    return solution\n","test":"assert f(startnum = 1, endnum = 10).shape[0] == <ground_truth>","result":"3","code_lines":9,"cyclomatic_complexity":1,"common_api_count":1}
{"ID":"45","code":"import numpy as np\nimport pandas as pd\ndef f():\n    values = np.linspace(0, 100, 50)\n    hist, bins = np.histogram(values, bins=10)\n\n    hist_data = {'Bin': bins[:-1], 'Frequency': hist}\n    hist_df = pd.DataFrame(hist_data)\n\n    summary_stats = hist_df.describe()\n    cleaned_df = hist_df.dropna()\n\n    melted_df = cleaned_df.melt(id_vars='Bin', value_vars='Frequency')\n    return melted_df\n","test":"assert f().shape[0] == <ground_truth>","result":"10","code_lines":9,"cyclomatic_complexity":1,"common_api_count":6}
{"ID":"46","code":"import numpy as np\nimport pandas as pd\n\n\ndef f():\n    values = np.linspace(0, 100, 100)\n    hist, bins = np.histogram(values, bins=5)\n\n    hist_data = {'Bin': bins[:-1], 'Frequency': hist}\n    hist_df = pd.DataFrame(hist_data)\n\n    grouped = hist_df.groupby('Bin').agg({'Frequency': ['sum', 'mean']})\n    grouped.columns = ['Sum', 'Mean']\n\n    pivot_table = grouped.pivot_table(index='Bin', values=['Sum', 'Mean'])\n\n    cleaned_table = pivot_table.dropna()\n\n\n    return cleaned_table\n","test":"assert list(f().columns)[0] == <ground_truth>","result":"'Mean'","code_lines":10,"cyclomatic_complexity":1,"common_api_count":4}
{"ID":"47","code":"import numpy as np\nimport pandas as pd\n\n\ndef f(n, m):\n    zeros_array = np.zeros((n, m))\n    ones_array = np.ones((m, n))\n\n    transposed_ones = np.transpose(ones_array)\n    combined_array = np.concatenate((zeros_array, transposed_ones), axis=0)\n\n    df = pd.DataFrame(combined_array)\n    last_rows = df.tail(5)\n\n    return last_rows\n","test":"assert f(3, 4).iloc[1][1] == <ground_truth>","result":"0","code_lines":8,"cyclomatic_complexity":1,"common_api_count":6}
{"ID":"48","code":"import numpy as np\nimport pandas as pd\n\n\ndef f(start_num1, end_num1, start_num2, end_num2):\n    array1 = np.linspace(start_num1, end_num1, 6).reshape(2, 3)\n    array2 = np.linspace(start_num2, end_num2, 6).reshape(2, 3)\n\n    addition_result = np.add(array1, array2)\n    multiplication_result = np.multiply(array1, array2)\n    dot_product_result = np.dot(array1, array2.T)\n\n    df = pd.DataFrame(dot_product_result)\n    df_shape = df.shape\n\n    return addition_result, multiplication_result, df_shape\n","test":"addition_result, multiplication_result, df_shape = f(1, 6, 6, 11)\nassert df_shape == <ground_truth>","result":"(2, 2)","code_lines":9,"cyclomatic_complexity":1,"common_api_count":6}
{"ID":"49","code":"import numpy as np\nimport pandas as pd\n\ndef f():\n    zero_array = np.zeros((3, 3))\n    stacked_array = np.vstack((zero_array, zero_array))\n    df = pd.DataFrame(stacked_array, columns=['A', 'B', 'C'])\n\n    df_sorted = df.sort_values(by='B', ascending=False)\n    selected_rows = df_sorted.iloc[:2]\n    grouped_counts = df_sorted.groupby('C').count()\n    return selected_rows, grouped_counts\n","test":"selected_rows, grouped_counts = f()\nassert grouped_counts.iloc[0][0] == <ground_truth>","result":"6","code_lines":8,"cyclomatic_complexity":1,"common_api_count":6}
