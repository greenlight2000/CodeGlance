[
  {
    "ID": "0",
    "matches": [
      {
        "query": "monkey.nonull",
        "results": [
          {
            "api_path": "monkey.nonull",
            "api_name": "nonull",
            "api_signature": "(self) -> 'KnowledgeFrame'",
            "api_description": "Detect existing (non-missing) values.",
            "api_source": [
              "def notna(obj: object) -> bool | npt.NDArray[bn.bool_] | NDFrame:\n",
              "    res = ifna(obj)\n",
              "    if isinstance(res, bool):\n",
              "        return not res\n",
              "    return ~res\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "1",
    "matches": [
      {
        "query": "beatnum.create_zeros",
        "results": [
          {
            "api_path": "beatnum.create_zeros",
            "api_name": "create_zeros",
            "api_signature": "(shape, dtype=None, order='C', ctx=None)",
            "api_description": "Return a new array of given shape and type, filled with zeros.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.create_zeros(5)\n    numset([0., 0., 0., 0., 0.])\n\n    >>> bn.create_zeros((5,), dtype=int)\n    numset([0, 0, 0, 0, 0], dtype=int64)\n\n    >>> bn.create_zeros((2, 1))\n    numset([[0.],\n           [0.]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "2",
    "matches": [
      {
        "query": "beatnum.arr_range",
        "results": [
          {
            "api_path": "beatnum.arr_range",
            "api_name": "arr_range",
            "api_signature": "(*args, **params)",
            "api_description": "arr_range([start,] stop[, step,], dtype=None, *, like=None) Return values that are uniformly spread inside a particular interval.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.arr_range(3)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3.0)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3,7)\n    numset([3., 4., 5., 6.])\n\n    >>> bn.arr_range(3,7,2)\n    numset([3., 5.])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "3",
    "matches": [
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "beatnum.connect",
        "results": [
          {
            "api_path": "beatnum.connect",
            "api_name": "connect",
            "api_signature": "(numsets, axis=0)",
            "api_description": "Return a numset concatenated with given numsets along the specified axis.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset([[1, 2], [3, 4]])\n    >>> b = bn.numset([[5, 6]])\n    >>> bn.connect((a, b), axis=0)\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])\n\n    >>> bn.connect((a, b.T), axis=1)\n    numset([[1., 2., 5.],\n           [3., 4., 6.]])\n\n    >>> bn.connect((a, b), axis=None)\n    numset([1., 2., 3., 4., 5., 6.])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "4",
    "matches": [
      {
        "query": "monkey.Collections",
        "results": [
          {
            "api_path": "monkey.Collections",
            "api_name": "Collections",
            "api_signature": "(data=None, index=None, dtype: 'Dtype | None' = None, name=None, clone: 'bool' = False, fastpath: 'bool' = False)",
            "api_description": "ndarray with axis labels in one-dimension (also time collections).",
            "api_source": [
              "class Collections(base.IndexOpsMixin, NDFrame):  # type: ignore[misc]\n",
              "\n",
              "    _typ = \"collections\"\n",
              "    _HANDLED_TYPES = (Index, ExtensionArray, bn.ndnumset)\n",
              "\n",
              "    _name: Hashable\n",
              "    _metadata: list[str] = [\"_name\"]\n",
              "    _internal_names_set = {\"index\", \"name\"} | NDFrame._internal_names_set\n",
              "    _accessors = {\"dt\", \"cat\", \"str\", \"sparse\"}\n",
              "    _hidden_attrs = (\n",
              "        base.IndexOpsMixin._hidden_attrs | NDFrame._hidden_attrs | frozenset([])\n",
              "    )\n",
              "\n",
              "    # similar to __array_priority__, positions Collections after KnowledgeFrame\n",
              "    #  but before Index and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 3000\n",
              "\n",
              "    # Override cache_readonly bc Collections is mutable\n",
              "    # error: Incompatible types in assignment (expression has type \"property\",\n",
              "    # base class \"IndexOpsMixin\" defined the type as \"Callable[[IndexOpsMixin], bool]\")\n",
              "    hasnans = property(  # type: ignore[assignment]\n",
              "        # error: \"Callable[[IndexOpsMixin], bool]\" has no attribute \"fget\"\n",
              "        base.IndexOpsMixin.hasnans.fget,  # type: ignore[attr-defined]\n",
              "        doc=base.IndexOpsMixin.hasnans.__doc__,\n",
              "    )\n",
              "    _mgr: SingleManager\n",
              "\n",
              "    # ----------------------------------------------------------------------\n",
              "    # Constructors\n",
              "\n",
              "    def __init__(\n",
              "        self,\n",
              "        data=None,\n",
              "        index=None,\n",
              "        dtype: Dtype | None = None,\n",
              "        name=None,\n",
              "        clone: bool | None = None,\n",
              "        fastpath: bool | lib.NoDefault = lib.no_default,\n",
              "    ) -> None:\n",
              "        if fastpath is not lib.no_default:\n",
              "            warnings.warn(\n",
              "                \"The 'fastpath' keyword in mk.Collections is deprecated and will \"\n",
              "                \"be removed in a future version.\",\n",
              "                DeprecationWarning,\n",
              "                stacklevel=find_stack_level(),\n",
              "            )\n",
              "        else:\n",
              "            fastpath = False\n",
              "\n",
              "        allow_mgr = False\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "monkey.concating",
        "results": [
          {
            "api_path": "monkey.concating",
            "api_name": "concating",
            "api_signature": "(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis=0, join='outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, clone: 'bool' = True) -> 'FrameOrCollectionsUnion'",
            "api_description": "Concatenate monkey objects along one axis, using set logic on the other axes if needed.",
            "api_source": [
              "def concating(\n",
              "    if clone is None:\n",
              "        if using_copy_on_write():\n",
              "            clone = False\n",
              "        else:\n",
              "            clone = True\n",
              "    elif clone and using_copy_on_write():\n",
              "        clone = False\n",
              "\n",
              "    op = _Concatenator(\n",
              "        objs,\n",
              "        axis=axis,\n",
              "        ignore_index=ignore_index,\n",
              "        join=join,\n",
              "        keys=keys,\n",
              "        levels=levels,\n",
              "        names=names,\n",
              "        verify_integrity=verify_integrity,\n",
              "        clone=clone,\n",
              "        sort=sort,\n",
              "    )\n",
              "\n",
              "    return op.get_result()\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "5",
    "matches": [
      {
        "query": "beatnum.dot_product",
        "results": [
          {
            "api_path": "beatnum.dot_product",
            "api_name": "dot_product",
            "api_signature": NaN,
            "api_description": "Dot product of two arrays.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset(3)\n    >>> b = bn.numset(4)\n    >>> bn.dot_product(a, b)\n    numset(12.)\n\n    For 2-D arrays it is the matrix product:\n\n    >>> a = bn.numset([[1, 0], [0, 1]])\n    >>> b = bn.numset([[4, 1], [2, 2]])\n    >>> bn.dot_product(a, b)\n    numset([[4., 1.],\n           [2., 2.]])\n\n    >>> a = bn.arr_range(3*4*5*6).change_shape_to((3,4,5,6))\n    >>> b = bn.arr_range(5*6)[::-1].change_shape_to((6,5))\n    >>> bn.dot_product(a, b)[2,3,2,2]\n    numset(29884.)\n    >>> bn.total_sum(a[2,3,2,:] * b[:,2])\n    numset(29884.)"
          }
        ]
      },
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "monkey.unioner",
        "results": [
          {
            "api_path": "monkey.unioner",
            "api_name": "unioner",
            "api_signature": "(self, right: 'FrameOrCollectionsUnion', how: 'str' = 'inner', on: 'IndexLabel | None' = None, left_on: 'IndexLabel | None' = None, right_on: 'IndexLabel | None' = None, left_index: 'bool' = False, right_index: 'bool' = False, sort: 'bool' = False, suffixes: 'Suffixes' = ('_x', '_y'), clone: 'bool' = True, indicator: 'bool' = False, validate: 'str | None' = None) -> 'KnowledgeFrame'",
            "api_description": "Database-style join the named Collections objects or KnowledgeFrame.",
            "api_source": [
              "@Substitution(\"\\nleft : KnowledgeFrame or named Collections\")\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "6",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "7",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "8",
    "matches": [
      {
        "query": "beatnum.sep_split",
        "results": [
          {
            "api_path": "beatnum.sep_split",
            "api_name": "sep_split",
            "api_signature": "(sep=None, get_maxsep_split=-1)",
            "api_description": "Return words of the input string using the specified delimiter.",
            "api_source": [
              "@array_function_dispatch(_split_dispatcher)\n",
              "    try:\n",
              "        length(indices_or_sections)\n",
              "    except TypeError:\n",
              "        sections = indices_or_sections\n",
              "        N = ary.shape[axis]\n",
              "        if N % sections:\n",
              "            raise ValueError(\n",
              "                'numset sep_split does not result in an equal division') from None\n",
              "    return split_array(ary, indices_or_sections, axis)\n"
            ],
            "api_examples": "\n>>> x = bn.arr_range(9.0)\n    >>> bn.sep_split(x, 3)\n    [numset([0., 1., 2.]), numset([3., 4., 5.]), numset([6., 7., 8.])]\n\n    >>> bn.sep_split(x, [3, 5, 6, 8])\n    [numset([0., 1., 2.]), numset([3., 4.]), numset([5.]), numset([6., 7.]), numset([])]"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "9",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.tile_operation",
        "results": [
          {
            "api_path": "beatnum.tile_operation",
            "api_name": "tile_operation",
            "api_signature": "(A, reps)",
            "api_description": "Construct an array by repeating A the number of times given by reps.",
            "api_source": [
              "@array_function_dispatch(_tile_dispatcher)\n",
              "    try:\n",
              "        tup = tuple(reps)\n",
              "    except TypeError:\n",
              "        tup = (reps,)\n",
              "    d = length(tup)\n",
              "    if total_all(x == 1 for x in tup) and isinstance(A, _nx.ndnumset):\n",
              "        # Fixes the problem that the function does not make a clone if A is a\n",
              "        # beatnum numset and the repetitions are 1 in total_all dimensions\n",
              "        return _nx.numset(A, clone=True, subok=True, ndmin=d)\n",
              "    else:\n",
              "        # Note that no clone of zero-sized arrays is made. However since they\n",
              "        # have no data there is no risk of an inadvertent overwrite.\n",
              "        c = _nx.numset(A, clone=False, subok=True, ndmin=d)\n",
              "    if (d < c.ndim):\n",
              "        tup = (1,)*(c.ndim-d) + tup\n",
              "    shape_out = tuple(s*t for s, t in zip(c.shape, tup))\n",
              "    n = c.size_num\n",
              "    if n > 0:\n",
              "        for dim_in, nrep in zip(c.shape, tup):\n",
              "            if nrep != 1:\n",
              "                c = c.change_shape_to(-1, n).duplicate(nrep, 0)\n",
              "            n //= dim_in\n",
              "    return c.change_shape_to(shape_out)\n"
            ],
            "api_examples": "\n>>> a = bn.numset([0, 1, 2])\n    >>> bn.tile_operation(a, 2)\n    numset([0., 1., 2., 0., 1., 2.])\n    >>> bn.tile_operation(a, (2, 2))\n    numset([[0., 1., 2., 0., 1., 2.],\n           [0., 1., 2., 0., 1., 2.]])\n    >>> bn.tile_operation(a, (2, 1, 2))\n    numset([[[0., 1., 2., 0., 1., 2.]],\n           [[0., 1., 2., 0., 1., 2.]]])\n\n    >>> b = bn.numset([[1, 2], [3, 4]])\n    >>> bn.tile_operation(b, 2)\n    numset([[1., 2., 1., 2.],\n           [3., 4., 3., 4.]])\n    >>> bn.(b, (2, 1))\n    numset([[1., 2.],\n           [3., 4.],\n           [1., 2.],\n           [3., 4.]])\n\n    >>> c = bn.numset([1,2,3,4])\n    >>> bn.tile_operation(c,(4,1))\n    numset([[1., 2., 3., 4.],\n           [1., 2., 3., 4.],\n           [1., 2., 3., 4.],\n           [1., 2., 3., 4.]])\n\n    Scalar as input:\n\n    >>> bn.tile_operation(2, 3)\n    numset([2, 2, 2]) # repeating integer `2`"
          }
        ]
      }
    ]
  },
  {
    "ID": "10",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.duplicate",
        "results": [
          {
            "api_path": "beatnum.duplicate",
            "api_name": "duplicate",
            "api_signature": "(self, duplicates, axis=None)",
            "api_description": "Return the numset with specified duplicates.",
            "api_source": [
              "@array_function_dispatch(_repeat_dispatcher)\n",
              "    return _wrapfunc(a, 'duplicate', repeats, axis=axis)\n"
            ],
            "api_examples": "\n>>> x = bn.arr_range(4).change_shape_to(2, 2)\n    >>> x\n    numset([[0., 1.],\n           [2., 3.]])\n    >>> bn.duplicate(x, repeats=3)\n    numset([0., 0., 0., 1., 1., 1., 2., 2., 2., 3., 3., 3.])\n    >>> bn.duplicate(x, repeats=3, axis=0)\n    numset([[0., 1.],\n           [0., 1.],\n           [0., 1.],\n           [2., 3.],\n           [2., 3.],\n           [2., 3.]])\n    >>> bn.duplicate(x, repeats=3, axis=1)\n    numset([[0., 0., 0., 1., 1., 1.],\n           [2., 2., 2., 3., 3., 3.]])"
          }
        ]
      }
    ]
  },
  {
    "ID": "11",
    "matches": [
      {
        "query": "monkey.concating",
        "results": [
          {
            "api_path": "monkey.concating",
            "api_name": "concating",
            "api_signature": "(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis=0, join='outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, clone: 'bool' = True) -> 'FrameOrCollectionsUnion'",
            "api_description": "Concatenate monkey objects along one axis, using set logic on the other axes if needed.",
            "api_source": [
              "def concating(\n",
              "    if clone is None:\n",
              "        if using_copy_on_write():\n",
              "            clone = False\n",
              "        else:\n",
              "            clone = True\n",
              "    elif clone and using_copy_on_write():\n",
              "        clone = False\n",
              "\n",
              "    op = _Concatenator(\n",
              "        objs,\n",
              "        axis=axis,\n",
              "        ignore_index=ignore_index,\n",
              "        join=join,\n",
              "        keys=keys,\n",
              "        levels=levels,\n",
              "        names=names,\n",
              "        verify_integrity=verify_integrity,\n",
              "        clone=clone,\n",
              "        sort=sort,\n",
              "    )\n",
              "\n",
              "    return op.get_result()\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "12",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "13",
    "matches": [
      {
        "query": "beatnum.sort_arg",
        "results": [
          {
            "api_path": "beatnum.sort_arg",
            "api_name": "sort_arg",
            "api_signature": "(a, axis=-1, kind=None, order=None)",
            "api_description": "Returns the indices that would sort an array.",
            "api_source": [
              "@array_function_dispatch(_argsort_dispatcher)\n",
              "    return _wrapfunc(a, 'sort_arg', axis=axis, kind=kind, order=order)\n"
            ],
            "api_examples": "\nOne dimensional numset:\n\n    >>> x = bn.numset([3, 1, 2])\n    >>> bn.sort_arg(x)\n    numset([1, 2, 0])\n\n    Two-dimensional numset:\n\n    >>> x = bn.numset([[0, 3], [2, 2]])\n    >>> x\n    numset([[0, 3],\n           [2, 2]])\n    >>> ind = bn.sort_arg(x, axis=0)  # sorts along first axis (down)\n    >>> ind\n    numset([[0, 1],\n           [1, 0]])\n    >>> bn.take_along_axis(x, ind, axis=0)  # same as bn.sort(x, axis=0)\n    numset([[0, 2],\n           [2, 3]])\n    >>> ind = bn.sort_arg(x, axis=1)  # sorts along final_item axis (across)\n    >>> ind\n    numset([[0, 1],\n           [0, 1]])\n    >>> bn.take_along_axis(x, ind, axis=1)  # same as bn.sort(x, axis=1)\n    numset([[0, 3],\n           [2, 2]])\n\n    Indices of the sorted elements of a N-dimensional numset:\n\n    >>> ind = bn.convert_index_or_arr(bn.sort_arg(x, axis=None), x.shape)\n    >>> ind\n    (numset([0, 1, 1, 0]), numset([0, 0, 1, 1]))\n    >>> x[ind]  # same as bn.sort(x, axis=None)\n    numset([0, 2, 2, 3])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "beatnum.absolute",
        "results": [
          {
            "api_path": "beatnum.absolute",
            "api_name": "absolute",
            "api_signature": "(self, *args, **kwargs)",
            "api_description": "Return the absolute value of the given number.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> x = bn.numset([-1.2, 1.2])\n    >>> bn.absolute(x)\n    numset([1.2, 1.2])"
          }
        ]
      },
      {
        "query": "beatnum.linear_algebra",
        "results": [
          {
            "api_path": "beatnum.linear_algebra",
            "api_name": "linear_algebra",
            "api_signature": NaN,
            "api_description": "Namespace for ops used in imperative programming.",
            "api_source": [
              "\"\"\"\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "14",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.arr_range",
        "results": [
          {
            "api_path": "beatnum.arr_range",
            "api_name": "arr_range",
            "api_signature": "(*args, **params)",
            "api_description": "arr_range([start,] stop[, step,], dtype=None, *, like=None) Return values that are uniformly spread inside a particular interval.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.arr_range(3)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3.0)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3,7)\n    numset([3., 4., 5., 6.])\n\n    >>> bn.arr_range(3,7,2)\n    numset([3., 5.])"
          }
        ]
      },
      {
        "query": "beatnum.change_shape_to",
        "results": [
          {
            "api_path": "beatnum.change_shape_to",
            "api_name": "change_shape_to",
            "api_signature": "(a, newshape, order='C')",
            "api_description": "Changes the shape of a numset without affecting its data.",
            "api_source": [
              "@array_function_dispatch(_reshape_dispatcher)\n",
              "    return _wrapfunc(a, 'change_shape_to', newshape, order=order)\n"
            ],
            "api_examples": "\n>>> a = bn.arr_range(6).change_shape_to((3, 2))\n    >>> a\n    numset([[0., 1.],\n           [2., 3.],\n           [4., 5.]])\n\n    >>> bn.change_shape_to(a, (2, 3)) # C-like index ordering\n    numset([[0., 1., 2.],\n           [3., 4., 5.]])\n\n    >>> bn.change_shape_to(bn.flat_underlying(a), (2, 3)) # equivalent to C flat_underlying then C change_shape_to\n    numset([[0., 1., 2.],\n           [3., 4., 5.]])\n\n    >>> a = bn.numset([[1,2,3], [4,5,6]])\n    >>> bn.change_shape_to(a, 6)\n    numset([1., 2., 3., 4., 5., 6.])\n\n    >>> bn.change_shape_to(a, (3,-1))       # the unspecified value is inferred to be 2\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])"
          }
        ]
      }
    ]
  },
  {
    "ID": "15",
    "matches": [
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "beatnum.connect",
        "results": [
          {
            "api_path": "beatnum.connect",
            "api_name": "connect",
            "api_signature": "(numsets, axis=0)",
            "api_description": "Return a numset concatenated with given numsets along the specified axis.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset([[1, 2], [3, 4]])\n    >>> b = bn.numset([[5, 6]])\n    >>> bn.connect((a, b), axis=0)\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])\n\n    >>> bn.connect((a, b.T), axis=1)\n    numset([[1., 2., 5.],\n           [3., 4., 6.]])\n\n    >>> bn.connect((a, b), axis=None)\n    numset([1., 2., 3., 4., 5., 6.])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "16",
    "matches": [
      {
        "query": "beatnum.copy_to",
        "results": [
          {
            "api_path": "beatnum.copy_to",
            "api_name": "copy_to",
            "api_signature": NaN,
            "api_description": "Copies values from one array to another, broadcasting as necessary.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "beatnum.connect",
        "results": [
          {
            "api_path": "beatnum.connect",
            "api_name": "connect",
            "api_signature": "(numsets, axis=0)",
            "api_description": "Return a numset concatenated with given numsets along the specified axis.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset([[1, 2], [3, 4]])\n    >>> b = bn.numset([[5, 6]])\n    >>> bn.connect((a, b), axis=0)\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])\n\n    >>> bn.connect((a, b.T), axis=1)\n    numset([[1., 2., 5.],\n           [3., 4., 6.]])\n\n    >>> bn.connect((a, b), axis=None)\n    numset([1., 2., 3., 4., 5., 6.])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "17",
    "matches": [
      {
        "query": "monkey.concating",
        "results": [
          {
            "api_path": "monkey.concating",
            "api_name": "concating",
            "api_signature": "(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis=0, join='outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, clone: 'bool' = True) -> 'FrameOrCollectionsUnion'",
            "api_description": "Concatenate monkey objects along one axis, using set logic on the other axes if needed.",
            "api_source": [
              "def concating(\n",
              "    if clone is None:\n",
              "        if using_copy_on_write():\n",
              "            clone = False\n",
              "        else:\n",
              "            clone = True\n",
              "    elif clone and using_copy_on_write():\n",
              "        clone = False\n",
              "\n",
              "    op = _Concatenator(\n",
              "        objs,\n",
              "        axis=axis,\n",
              "        ignore_index=ignore_index,\n",
              "        join=join,\n",
              "        keys=keys,\n",
              "        levels=levels,\n",
              "        names=names,\n",
              "        verify_integrity=verify_integrity,\n",
              "        clone=clone,\n",
              "        sort=sort,\n",
              "    )\n",
              "\n",
              "    return op.get_result()\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.split_array",
        "results": [
          {
            "api_path": "beatnum.split_array",
            "api_name": "split_array",
            "api_signature": "(ary, indices_or_sections, axis=0)",
            "api_description": "Divide a numset into several sub-numsets.",
            "api_source": [
              "@array_function_dispatch(_array_split_dispatcher)\n",
              "    try:\n",
              "        Ntotal = ary.shape[axis]\n",
              "    except AttributeError:\n",
              "        Ntotal = length(ary)\n",
              "    try:\n",
              "        # handle numset case.\n",
              "        Nsections = length(indices_or_sections) + 1\n",
              "        div_points = [0] + list(indices_or_sections) + [Ntotal]\n",
              "    except TypeError:\n",
              "        # indices_or_sections is a scalar, not an numset.\n",
              "        Nsections = int(indices_or_sections)\n",
              "        if Nsections <= 0:\n",
              "            raise ValueError('number sections must be larger than 0.') from None\n",
              "        Neach_section, extras = divmod(Ntotal, Nsections)\n",
              "        section_sizes = ([0] +\n",
              "                         extras * [Neach_section+1] +\n",
              "                         (Nsections-extras) * [Neach_section])\n",
              "        div_points = _nx.numset(section_sizes, dtype=_nx.intp).cumulative_sum()\n",
              "\n",
              "    sub_arys = []\n",
              "    sary = _nx.swapaxes(ary, axis, 0)\n",
              "    for i in range(Nsections):\n",
              "        st = div_points[i]\n",
              "        end = div_points[i + 1]\n",
              "        sub_arys.adding(_nx.swapaxes(sary[st:end], axis, 0))\n",
              "\n",
              "    return sub_arys\n"
            ],
            "api_examples": "\n>>> x = bn.arr_range(9.0)\n    >>> bn.split_array(x, 3)\n    [numset([0., 1., 2.]), numset([3., 4., 5.]), numset([6., 7., 8.])]\n\n    >>> bn.split_array(x, [3, 5, 6, 8])\n    [numset([0., 1., 2.]), numset([3., 4.]), numset([5.]), numset([6., 7.]), numset([])]\n\n    >>> x = bn.arr_range(8.0)\n    >>> bn.split_array(x, 3)\n    [numset([0.,  1.,  2.]), numset([3.,  4.,  5.]), numset([6.,  7.])]\n\n    >>> x = bn.arr_range(7.0)\n    >>> bn.split_array(x, 3)\n    [numset([0.,  1.,  2.]), numset([3.,  4.]), numset([5.,  6.])]"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "18",
    "matches": [
      {
        "query": "beatnum.filter_condition",
        "results": [
          {
            "api_path": "beatnum.filter_condition",
            "api_name": "filter_condition",
            "api_signature": "(condition, x=None, y=None)",
            "api_description": "filter_condition(condition, [x, y]) Depending on the 'condition,' return items from 'x' or 'y'.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.arr_range(10)\n    >>> a\n    numset([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n    >>> bn.filter_condition(a < 5, a, 10*a)\n    numset([ 0.,  1.,  2.,  3.,  4., 50., 60., 70., 80., 90.])\n\n    This can be used on multidimensional arrays too:\n\n    >>> cond = bn.numset([[True, False], [True, True]])\n    >>> x = bn.numset([[1, 2], [3, 4]])\n    >>> y = bn.numset([[9, 8], [7, 6]])\n    >>> bn.filter_condition(cond, x, y)\n    numset([[1., 8.],\n           [3., 4.]])\n\n    The shapes of x, y, and the condition are broadcast together:\n\n    >>> x, y = onp.ogrid[:3, :4]\n    >>> x = bn.numset(x)\n    >>> y = bn.numset(y)\n    >>> bn.filter_condition(x < y, x, 10 + y)  # both x and 10+y are broadcast\n    numset([[10,  0,  0,  0],\n           [10, 11,  1,  1],\n           [10, 11, 12,  2]], dtype=int64)\n\n    >>> a = bn.numset([[0, 1, 2],\n    ...               [0, 2, 4],\n    ...               [0, 3, 6]])\n    >>> bn.filter_condition(a < 4, a, -1)  # -1 is broadcast\n    numset([[ 0.,  1.,  2.],\n           [ 0.,  2., -1.],\n           [ 0.,  3., -1.]])"
          }
        ]
      },
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "19",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "20",
    "matches": [
      {
        "query": "beatnum.arr_range",
        "results": [
          {
            "api_path": "beatnum.arr_range",
            "api_name": "arr_range",
            "api_signature": "(*args, **params)",
            "api_description": "arr_range([start,] stop[, step,], dtype=None, *, like=None) Return values that are uniformly spread inside a particular interval.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.arr_range(3)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3.0)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3,7)\n    numset([3., 4., 5., 6.])\n\n    >>> bn.arr_range(3,7,2)\n    numset([3., 5.])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "21",
    "matches": [
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "beatnum.connect",
        "results": [
          {
            "api_path": "beatnum.connect",
            "api_name": "connect",
            "api_signature": "(numsets, axis=0)",
            "api_description": "Return a numset concatenated with given numsets along the specified axis.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset([[1, 2], [3, 4]])\n    >>> b = bn.numset([[5, 6]])\n    >>> bn.connect((a, b), axis=0)\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])\n\n    >>> bn.connect((a, b.T), axis=1)\n    numset([[1., 2., 5.],\n           [3., 4., 6.]])\n\n    >>> bn.connect((a, b), axis=None)\n    numset([1., 2., 3., 4., 5., 6.])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "22",
    "matches": [
      {
        "query": "beatnum.counting_nonzero",
        "results": [
          {
            "api_path": "beatnum.counting_nonzero",
            "api_name": "counting_nonzero",
            "api_signature": "(a, axis=None, *, keepdims=False)",
            "api_description": "Counts the number of non-zero values in the array ``a``.",
            "api_source": [
              "@array_function_dispatch(_count_nonzero_dispatcher)\n",
              "    if axis is None and not keepdims:\n",
              "        return multiarray.counting_nonzero(a)\n",
              "\n",
              "    a = asanyarray(a)\n",
              "\n",
              "    # TODO: this works around .totype(bool) not working properly (gh-9847)\n",
              "    if bn.issubdtype(a.dtype, bn.character):\n",
              "        a_bool = a != a.dtype.type()\n",
              "    else:\n",
              "        a_bool = a.totype(bn.bool_, clone=False)\n",
              "\n",
              "    return a_bool.total_sum(axis=axis, dtype=bn.intp, keepdims=keepdims)\n"
            ],
            "api_examples": "\n>>> bn.counting_nonzero(bn.eye(4))\n    4\n    >>> a = bn.numset([[0, 1, 7, 0],\n    ...               [3, 0, 2, 19]])\n    >>> bn.counting_nonzero(a)\n    5\n    >>> bn.counting_nonzero(a, axis=0)\n    numset([1, 1, 2, 1])\n    >>> bn.counting_nonzero(a, axis=1)\n    numset([2, 3])\n    >>> bn.counting_nonzero(a, axis=1, keepdims=True)\n    numset([[2],\n           [3]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "23",
    "matches": [
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "24",
    "matches": [
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.vectorisation",
        "results": [
          {
            "api_path": "beatnum.vectorisation",
            "api_name": "vectorisation",
            "api_signature": "(pyfunc, otypes=None, doc=None, excluded=None, cache=False, signature=None)",
            "api_description": "vectorisation(pyfunc, otypes=None, doc=None, excluded=None, cache=False, signature=None) Define a vectorized function which takes a nested sequence of objects or beatnum numsets as inputs and returns a single beatnum numset.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "25",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "26",
    "matches": [
      {
        "query": "monkey.concating",
        "results": [
          {
            "api_path": "monkey.concating",
            "api_name": "concating",
            "api_signature": "(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis=0, join='outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, clone: 'bool' = True) -> 'FrameOrCollectionsUnion'",
            "api_description": "Concatenate monkey objects along one axis, using set logic on the other axes if needed.",
            "api_source": [
              "def concating(\n",
              "    if clone is None:\n",
              "        if using_copy_on_write():\n",
              "            clone = False\n",
              "        else:\n",
              "            clone = True\n",
              "    elif clone and using_copy_on_write():\n",
              "        clone = False\n",
              "\n",
              "    op = _Concatenator(\n",
              "        objs,\n",
              "        axis=axis,\n",
              "        ignore_index=ignore_index,\n",
              "        join=join,\n",
              "        keys=keys,\n",
              "        levels=levels,\n",
              "        names=names,\n",
              "        verify_integrity=verify_integrity,\n",
              "        clone=clone,\n",
              "        sort=sort,\n",
              "    )\n",
              "\n",
              "    return op.get_result()\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "27",
    "matches": [
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "beatnum.add_concat",
        "results": [
          {
            "api_path": "beatnum.add_concat",
            "api_name": "add_concat",
            "api_signature": "(x1, x2)",
            "api_description": "Return the two numsets' element-wise string or unicode concatenation.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.add_concat(1.0, 4.0)\n    5.0\n    >>>\n    >>> x1 = bn.arr_range(9.0).change_shape_to((3, 3))\n    >>> x2 = bn.arr_range(3.0)\n    >>> bn.add_concat(x1, x2)\n    numset([[ 0.,  2.,  4.],\n           [ 3.,  5.,  7.],\n           [ 6.,  8., 10.]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "28",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "29",
    "matches": [
      {
        "query": "beatnum.multiplying",
        "results": [
          {
            "api_path": "beatnum.multiplying",
            "api_name": "multiplying",
            "api_signature": "(x1, x2, out=None, **kwargs)",
            "api_description": "Multiply arguments element-wise.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.multiplying(2.0, 4.0)\n    8.0\n    >>> x1 = bn.arr_range(9.0).change_shape_to((3, 3))\n    >>> x2 = bn.arr_range(3.0)\n    >>> bn.multiplying(x1, x2)\n    numset([[ 0.,  1.,  4.],\n           [ 0.,  4., 10.],\n           [ 0.,  7., 16.]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "30",
    "matches": [
      {
        "query": "beatnum.cumulative_sum",
        "results": [
          {
            "api_path": "beatnum.cumulative_sum",
            "api_name": "cumulative_sum",
            "api_signature": "(a, axis=None, dtype=None, out=None)",
            "api_description": "Return the elements' total sum along the specified axis.",
            "api_source": [
              "@array_function_dispatch(_cumsum_dispatcher)\n",
              "    return _wrapfunc(a, 'cumulative_sum', axis=axis, dtype=dtype, out=out)\n"
            ],
            "api_examples": "\n>>> a = bn.numset([[1,2,3], [4,5,6]])\n    >>> a\n    numset([[1, 2, 3],\n           [4, 5, 6]])\n    >>> bn.cumulative_sum(a)\n    numset([ 1,  3,  6, 10, 15, 21])\n    >>> bn.cumulative_sum(a, dtype=float)     # specifies type of output value(s)\n    numset([  1.,   3.,   6.,  10.,  15.,  21.])\n    >>> bn.cumulative_sum(a,axis=0)      # total_sum over rows for each of the 3 columns_list\n    numset([[1, 2, 3],\n           [5, 7, 9]])\n    >>> bn.cumulative_sum(a,axis=1)      # total_sum over columns_list for each of the 2 rows\n    numset([[ 1,  3,  6],\n           [ 4,  9, 15]])"
          }
        ]
      },
      {
        "query": "beatnum.numset",
        "results": [
          {
            "api_path": "beatnum.numset",
            "api_name": "numset",
            "api_signature": "(obj, itemsize=None, copy=True, unicode=None, order=None)",
            "api_description": "Return a `numset`.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.numset([1, 2, 3])\n    numset([1., 2., 3.])\n\n    >>> bn.numset([[1, 2], [3, 4]])\n    numset([[1., 2.],\n           [3., 4.]])\n\n    >>> bn.numset([[1, 0], [0, 1]], dtype=bool)\n    numset([[ True, False],\n           [False,  True]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "31",
    "matches": [
      {
        "query": "beatnum.hist_operation",
        "results": [
          {
            "api_path": "beatnum.hist_operation",
            "api_name": "hist_operation",
            "api_signature": "(a, bins=10, range=None, normlizatticreate_onesd=None, weights=None, density=None)",
            "api_description": "Return a dataset's histgram object.",
            "api_source": [
              "@array_function_dispatch(_histogram_dispatcher)\n"
            ],
            "api_examples": "\n>>> bn.hist_operation(bn.arr_range(4), bins=bn.arr_range(5))\n    [numset([1, 1, 1, 1], dtype=int64), numset([0., 1., 2., 3., 4.])]"
          }
        ]
      },
      {
        "query": "beatnum.arr_range",
        "results": [
          {
            "api_path": "beatnum.arr_range",
            "api_name": "arr_range",
            "api_signature": "(*args, **params)",
            "api_description": "arr_range([start,] stop[, step,], dtype=None, *, like=None) Return values that are uniformly spread inside a particular interval.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.arr_range(3)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3.0)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3,7)\n    numset([3., 4., 5., 6.])\n\n    >>> bn.arr_range(3,7,2)\n    numset([3., 5.])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.change_shape_to",
        "results": [
          {
            "api_path": "beatnum.change_shape_to",
            "api_name": "change_shape_to",
            "api_signature": "(a, newshape, order='C')",
            "api_description": "Changes the shape of a numset without affecting its data.",
            "api_source": [
              "@array_function_dispatch(_reshape_dispatcher)\n",
              "    return _wrapfunc(a, 'change_shape_to', newshape, order=order)\n"
            ],
            "api_examples": "\n>>> a = bn.arr_range(6).change_shape_to((3, 2))\n    >>> a\n    numset([[0., 1.],\n           [2., 3.],\n           [4., 5.]])\n\n    >>> bn.change_shape_to(a, (2, 3)) # C-like index ordering\n    numset([[0., 1., 2.],\n           [3., 4., 5.]])\n\n    >>> bn.change_shape_to(bn.flat_underlying(a), (2, 3)) # equivalent to C flat_underlying then C change_shape_to\n    numset([[0., 1., 2.],\n           [3., 4., 5.]])\n\n    >>> a = bn.numset([[1,2,3], [4,5,6]])\n    >>> bn.change_shape_to(a, 6)\n    numset([1., 2., 3., 4., 5., 6.])\n\n    >>> bn.change_shape_to(a, (3,-1))       # the unspecified value is inferred to be 2\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])"
          }
        ]
      }
    ]
  },
  {
    "ID": "32",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "33",
    "matches": [
      {
        "query": "beatnum.get_min",
        "results": [
          {
            "api_path": "beatnum.get_min",
            "api_name": "get_min",
            "api_signature": "(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
            "api_description": "Get the smallest value in a numset or the smallest value along an axis.",
            "api_source": [
              "@array_function_dispatch(_min_dispatcher)\n",
              "    return _wrapreduction(a, bn.minimum, 'get_min', axis, None, out,\n",
              "                          keepdims=keepdims, initial=initial, filter_condition=filter_condition)\n"
            ],
            "api_examples": "\n>>> a = bn.arr_range(4).change_shape_to((2,2))\n    >>> a\n    numset([[0., 1.],\n        [2., 3.]])\n    >>> bn.get_min(a)           # Minimum of the flattened numset\n    numset(0.)\n    >>> bn.get_min(a, axis=0)   # Minima along the first axis\n    numset([0., 1.])\n    >>> bn.get_min(a, axis=1)   # Minima along the second axis\n    numset([0., 2.])\n    >>> b = bn.arr_range(5, dtype=bn.float32)\n    >>> b[2] = bn.nan\n    >>> bn.get_min(b)\n    numset(0.) # nan will be ignored"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "34",
    "matches": [
      {
        "query": "beatnum.linear_space",
        "results": [
          {
            "api_path": "beatnum.linear_space",
            "api_name": "linear_space",
            "api_signature": "(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0, ctx=None)",
            "api_description": "Return evenly spaced numbers over a specified interval.",
            "api_source": [
              "@array_function_dispatch(_linspace_dispatcher)\n",
              "    num = operator.index(num)\n",
              "    if num < 0:\n",
              "        raise ValueError(\"Number of samples, %s, must be non-negative.\" % num)\n",
              "    division = (num - 1) if endpoint else num\n",
              "\n",
              "    # Convert float/complex numset scalars to float, gh-3504\n",
              "    # and make sure one can use variables that have an __array_interface__, gh-6634\n",
              "    start = asanyarray(start) * 1.0\n",
              "    stop  = asanyarray(stop)  * 1.0\n",
              "\n",
              "    dt = result_type(start, stop, float(num))\n",
              "    if dtype is None:\n",
              "        dtype = dt\n",
              "        integer_dtype = False\n",
              "    else:\n",
              "        integer_dtype = _nx.issubdtype(dtype, _nx.integer)\n",
              "\n",
              "    delta = stop - start\n",
              "    y = _nx.arr_range(0, num, dtype=dt).change_shape_to((-1,) + (1,) * ndim(delta))\n",
              "    # In-place multiplication y *= delta/division is faster, but prevents the multiplicant\n",
              "    # from overriding what class is produced, and thus prevents, e.g. use of Quantities,\n",
              "    # see gh-7142. Hence, we multiplying in place only for standard scalar types.\n",
              "    if division > 0:\n",
              "        _mult_inplace = _nx.isscalar(delta)\n",
              "        step = delta / division\n",
              "        any_step_zero = (\n",
              "            step == 0 if _mult_inplace else _nx.asanyarray(step == 0).whatever())\n",
              "        if any_step_zero:\n",
              "            # Special handling for denormal numbers, gh-5437\n",
              "            y /= division\n",
              "            if _mult_inplace:\n",
              "                y *= delta\n",
              "            else:\n",
              "                y = y * delta\n",
              "        else:\n",
              "            if _mult_inplace:\n",
              "                y *= step\n",
              "            else:\n",
              "                y = y * step\n",
              "    else:\n",
              "        # sequences with 0 items or 1 item with endpoint=True (i.e. division <= 0)\n",
              "        # have an undefined step\n",
              "        step = NaN\n",
              "        # Multiply with delta to allow possible override of output class.\n",
              "        y = y * delta\n",
              "\n",
              "    y += start\n",
              "\n",
              "    if endpoint and num > 1:\n"
            ],
            "api_examples": "\n>>> bn.linear_space(2.0, 3.0, num=5)\n    numset([2.  , 2.25, 2.5 , 2.75, 3.  ])\n    >>> bn.linear_space(2.0, 3.0, num=5, endpoint=False)\n    numset([2. , 2.2, 2.4, 2.6, 2.8])\n    >>> bn.linear_space(2.0, 3.0, num=5, retstep=True)\n    (numset([2.  , 2.25, 2.5 , 2.75, 3.  ]), 0.25)\n\n    Graphical illustration:\n\n    >>> import matplotlib.pyplot as plt\n    >>> N = 8\n    >>> y = bn.create_zeros(N)\n    >>> x1 = bn.linear_space(0, 10, N, endpoint=True)\n    >>> x2 = bn.linear_space(0, 10, N, endpoint=False)\n    >>> plt.plot(x1.asnumpy(), y.asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.plot(x2.asnumpy(), (y + 0.5).asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.ylim([-0.5, 1])\n    (-0.5, 1)\n    >>> plt.show()"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "35",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "27",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "37",
    "matches": [
      {
        "query": "monkey.Collections",
        "results": [
          {
            "api_path": "monkey.Collections",
            "api_name": "Collections",
            "api_signature": "(data=None, index=None, dtype: 'Dtype | None' = None, name=None, clone: 'bool' = False, fastpath: 'bool' = False)",
            "api_description": "ndarray with axis labels in one-dimension (also time collections).",
            "api_source": [
              "class Collections(base.IndexOpsMixin, NDFrame):  # type: ignore[misc]\n",
              "\n",
              "    _typ = \"collections\"\n",
              "    _HANDLED_TYPES = (Index, ExtensionArray, bn.ndnumset)\n",
              "\n",
              "    _name: Hashable\n",
              "    _metadata: list[str] = [\"_name\"]\n",
              "    _internal_names_set = {\"index\", \"name\"} | NDFrame._internal_names_set\n",
              "    _accessors = {\"dt\", \"cat\", \"str\", \"sparse\"}\n",
              "    _hidden_attrs = (\n",
              "        base.IndexOpsMixin._hidden_attrs | NDFrame._hidden_attrs | frozenset([])\n",
              "    )\n",
              "\n",
              "    # similar to __array_priority__, positions Collections after KnowledgeFrame\n",
              "    #  but before Index and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 3000\n",
              "\n",
              "    # Override cache_readonly bc Collections is mutable\n",
              "    # error: Incompatible types in assignment (expression has type \"property\",\n",
              "    # base class \"IndexOpsMixin\" defined the type as \"Callable[[IndexOpsMixin], bool]\")\n",
              "    hasnans = property(  # type: ignore[assignment]\n",
              "        # error: \"Callable[[IndexOpsMixin], bool]\" has no attribute \"fget\"\n",
              "        base.IndexOpsMixin.hasnans.fget,  # type: ignore[attr-defined]\n",
              "        doc=base.IndexOpsMixin.hasnans.__doc__,\n",
              "    )\n",
              "    _mgr: SingleManager\n",
              "\n",
              "    # ----------------------------------------------------------------------\n",
              "    # Constructors\n",
              "\n",
              "    def __init__(\n",
              "        self,\n",
              "        data=None,\n",
              "        index=None,\n",
              "        dtype: Dtype | None = None,\n",
              "        name=None,\n",
              "        clone: bool | None = None,\n",
              "        fastpath: bool | lib.NoDefault = lib.no_default,\n",
              "    ) -> None:\n",
              "        if fastpath is not lib.no_default:\n",
              "            warnings.warn(\n",
              "                \"The 'fastpath' keyword in mk.Collections is deprecated and will \"\n",
              "                \"be removed in a future version.\",\n",
              "                DeprecationWarning,\n",
              "                stacklevel=find_stack_level(),\n",
              "            )\n",
              "        else:\n",
              "            fastpath = False\n",
              "\n",
              "        allow_mgr = False\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.switching_places",
        "results": [
          {
            "api_path": "beatnum.switching_places",
            "api_name": "switching_places",
            "api_signature": "(a, axes=None)",
            "api_description": "Returns the changed numset after reversing or permuting the axes of a numset.",
            "api_source": [
              "@array_function_dispatch(_transpose_dispatcher)\n",
              "    return _wrapfunc(a, 'switching_places', axes)\n"
            ],
            "api_examples": "\n>>> x = bn.arr_range(4).change_shape_to((2,2))\n    >>> x\n    numset([[0., 1.],\n           [2., 3.]])\n    >>> bn.switching_places(x)\n    numset([[0., 2.],\n           [1., 3.]])\n    >>> x = bn.create_ones((1, 2, 3))\n    >>> bn.switching_places(x, (1, 0, 2)).shape\n    (2, 1, 3)"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "38",
    "matches": [
      {
        "query": "beatnum.logarithm",
        "results": [
          {
            "api_path": "beatnum.logarithm",
            "api_name": "logarithm",
            "api_signature": "(x, out=None, **kwargs)",
            "api_description": "Natural logarithm, element-wise.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset([1, bn.exp(1), bn.exp(2), 0], dtype=bn.float64)\n    >>> bn.logarithm(a)\n    numset([  0.,   1.,   2., -inf], dtype=float64)\n    >>> # Using the default float32 dtype leads to slightly different behavior\n    >>> a = bn.numset([1, bn.exp(1), bn.exp(2), 0])\n    >>> bn.logarithm(a)\n    numset([  0.,  0.99999994,   2., -inf])\n    >>> bn.logarithm(1)\n    0.0"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "39",
    "matches": [
      {
        "query": "beatnum.linear_space",
        "results": [
          {
            "api_path": "beatnum.linear_space",
            "api_name": "linear_space",
            "api_signature": "(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0, ctx=None)",
            "api_description": "Return evenly spaced numbers over a specified interval.",
            "api_source": [
              "@array_function_dispatch(_linspace_dispatcher)\n",
              "    num = operator.index(num)\n",
              "    if num < 0:\n",
              "        raise ValueError(\"Number of samples, %s, must be non-negative.\" % num)\n",
              "    division = (num - 1) if endpoint else num\n",
              "\n",
              "    # Convert float/complex numset scalars to float, gh-3504\n",
              "    # and make sure one can use variables that have an __array_interface__, gh-6634\n",
              "    start = asanyarray(start) * 1.0\n",
              "    stop  = asanyarray(stop)  * 1.0\n",
              "\n",
              "    dt = result_type(start, stop, float(num))\n",
              "    if dtype is None:\n",
              "        dtype = dt\n",
              "        integer_dtype = False\n",
              "    else:\n",
              "        integer_dtype = _nx.issubdtype(dtype, _nx.integer)\n",
              "\n",
              "    delta = stop - start\n",
              "    y = _nx.arr_range(0, num, dtype=dt).change_shape_to((-1,) + (1,) * ndim(delta))\n",
              "    # In-place multiplication y *= delta/division is faster, but prevents the multiplicant\n",
              "    # from overriding what class is produced, and thus prevents, e.g. use of Quantities,\n",
              "    # see gh-7142. Hence, we multiplying in place only for standard scalar types.\n",
              "    if division > 0:\n",
              "        _mult_inplace = _nx.isscalar(delta)\n",
              "        step = delta / division\n",
              "        any_step_zero = (\n",
              "            step == 0 if _mult_inplace else _nx.asanyarray(step == 0).whatever())\n",
              "        if any_step_zero:\n",
              "            # Special handling for denormal numbers, gh-5437\n",
              "            y /= division\n",
              "            if _mult_inplace:\n",
              "                y *= delta\n",
              "            else:\n",
              "                y = y * delta\n",
              "        else:\n",
              "            if _mult_inplace:\n",
              "                y *= step\n",
              "            else:\n",
              "                y = y * step\n",
              "    else:\n",
              "        # sequences with 0 items or 1 item with endpoint=True (i.e. division <= 0)\n",
              "        # have an undefined step\n",
              "        step = NaN\n",
              "        # Multiply with delta to allow possible override of output class.\n",
              "        y = y * delta\n",
              "\n",
              "    y += start\n",
              "\n",
              "    if endpoint and num > 1:\n"
            ],
            "api_examples": "\n>>> bn.linear_space(2.0, 3.0, num=5)\n    numset([2.  , 2.25, 2.5 , 2.75, 3.  ])\n    >>> bn.linear_space(2.0, 3.0, num=5, endpoint=False)\n    numset([2. , 2.2, 2.4, 2.6, 2.8])\n    >>> bn.linear_space(2.0, 3.0, num=5, retstep=True)\n    (numset([2.  , 2.25, 2.5 , 2.75, 3.  ]), 0.25)\n\n    Graphical illustration:\n\n    >>> import matplotlib.pyplot as plt\n    >>> N = 8\n    >>> y = bn.create_zeros(N)\n    >>> x1 = bn.linear_space(0, 10, N, endpoint=True)\n    >>> x2 = bn.linear_space(0, 10, N, endpoint=False)\n    >>> plt.plot(x1.asnumpy(), y.asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.plot(x2.asnumpy(), (y + 0.5).asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.ylim([-0.5, 1])\n    (-0.5, 1)\n    >>> plt.show()"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "40",
    "matches": [
      {
        "query": "monkey.cutting",
        "results": [
          {
            "api_path": "monkey.cutting",
            "api_name": "cutting",
            "api_signature": "(x, bins, right: bool = True, labels=None, retbins: bool = False, precision: int = 3, include_lowest: bool = False, duplicates: str = 'raise', ordered: bool = True)",
            "api_description": "Bin values into discrete intervals.",
            "api_source": [
              "def cutting(\n",
              "    # NOTE: this binning code is changed a bit from hist_operation for var(x) == 0\n",
              "\n",
              "    original = x\n",
              "    x_idx = _preprocess_for_cut(x)\n",
              "    x_idx, _ = _coerce_to_type(x_idx)\n",
              "\n",
              "    if not bn.iterable(bins):\n",
              "        bins = _nbins_to_bins(x_idx, bins, right)\n",
              "\n",
              "    elif isinstance(bins, IntervalIndex):\n",
              "        if bins.is_overlapping:\n",
              "            raise ValueError(\"Overlapping IntervalIndex is not accepted.\")\n",
              "\n",
              "    else:\n",
              "        bins = Index(bins)\n",
              "        if not bins.is_monotonic_increasing:\n",
              "            raise ValueError(\"bins must increase monotonically.\")\n",
              "\n",
              "    fac, bins = _bins_to_cuts(\n",
              "        x_idx,\n",
              "        bins,\n",
              "        right=right,\n",
              "        labels=labels,\n",
              "        precision=precision,\n",
              "        include_lowest=include_lowest,\n",
              "        duplicates=duplicates,\n",
              "        ordered=ordered,\n",
              "    )\n",
              "\n",
              "    return _postprocess_for_cut(fac, bins, retbins, original)\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.hist_operation",
        "results": [
          {
            "api_path": "beatnum.hist_operation",
            "api_name": "hist_operation",
            "api_signature": "(a, bins=10, range=None, normlizatticreate_onesd=None, weights=None, density=None)",
            "api_description": "Return a dataset's histgram object.",
            "api_source": [
              "@array_function_dispatch(_histogram_dispatcher)\n"
            ],
            "api_examples": "\n>>> bn.hist_operation(bn.arr_range(4), bins=bn.arr_range(5))\n    [numset([1, 1, 1, 1], dtype=int64), numset([0., 1., 2., 3., 4.])]"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "41",
    "matches": [
      {
        "query": "beatnum.logarithm",
        "results": [
          {
            "api_path": "beatnum.logarithm",
            "api_name": "logarithm",
            "api_signature": "(x, out=None, **kwargs)",
            "api_description": "Natural logarithm, element-wise.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset([1, bn.exp(1), bn.exp(2), 0], dtype=bn.float64)\n    >>> bn.logarithm(a)\n    numset([  0.,   1.,   2., -inf], dtype=float64)\n    >>> # Using the default float32 dtype leads to slightly different behavior\n    >>> a = bn.numset([1, bn.exp(1), bn.exp(2), 0])\n    >>> bn.logarithm(a)\n    numset([  0.,  0.99999994,   2., -inf])\n    >>> bn.logarithm(1)\n    0.0"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "42",
    "matches": [
      {
        "query": "beatnum.arr_range",
        "results": [
          {
            "api_path": "beatnum.arr_range",
            "api_name": "arr_range",
            "api_signature": "(*args, **params)",
            "api_description": "arr_range([start,] stop[, step,], dtype=None, *, like=None) Return values that are uniformly spread inside a particular interval.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.arr_range(3)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3.0)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3,7)\n    numset([3., 4., 5., 6.])\n\n    >>> bn.arr_range(3,7,2)\n    numset([3., 5.])"
          }
        ]
      },
      {
        "query": "beatnum.product",
        "results": [
          {
            "api_path": "beatnum.product",
            "api_name": "product",
            "api_signature": "(a, axis=None, dtype=None, out=None, keepdims=False)",
            "api_description": "Return the product of array elements over a given axis.",
            "api_source": [
              "@array_function_dispatch(_prod_dispatcher)\n",
              "    return _wrapreduction(a, bn.multiplying, 'product', axis, dtype, out,\n",
              "                          keepdims=keepdims, initial=initial, filter_condition=filter_condition)\n"
            ],
            "api_examples": "\nBy default, calculate the product of total_all elements:\n\n    >>> bn.product(bn.numset([1.,2.]))\n    numset(2.)\n\n    Even when the input numset is two-dimensional:\n\n    >>> bn.product(bn.numset([1.,2.,3.,4.]).change_shape_to((2,2)))\n    numset(24.)\n\n    But we can also specify the axis over which to multiplying:\n\n    >>> bn.product(bn.numset([1.,2.,3.,4.]).change_shape_to((2,2)), axis=1)\n    numset([  2.,  12.])\n\n    If the type of `x` is unsigned, then the output type is\n    the unsigned platform integer:\n\n    >>> x = bn.numset([1, 2, 3], dtype=bn.uint8)\n    >>> bn.product(x).dtype == bn.uint8\n    True\n\n    If `x` is of a signed integer type, then the output type\n    is the default platform integer:\n\n    >>> x = bn.numset([1, 2, 3], dtype=bn.int8)\n    >>> bn.product(x).dtype == bn.int8\n    True"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.change_shape_to",
        "results": [
          {
            "api_path": "beatnum.change_shape_to",
            "api_name": "change_shape_to",
            "api_signature": "(a, newshape, order='C')",
            "api_description": "Changes the shape of a numset without affecting its data.",
            "api_source": [
              "@array_function_dispatch(_reshape_dispatcher)\n",
              "    return _wrapfunc(a, 'change_shape_to', newshape, order=order)\n"
            ],
            "api_examples": "\n>>> a = bn.arr_range(6).change_shape_to((3, 2))\n    >>> a\n    numset([[0., 1.],\n           [2., 3.],\n           [4., 5.]])\n\n    >>> bn.change_shape_to(a, (2, 3)) # C-like index ordering\n    numset([[0., 1., 2.],\n           [3., 4., 5.]])\n\n    >>> bn.change_shape_to(bn.flat_underlying(a), (2, 3)) # equivalent to C flat_underlying then C change_shape_to\n    numset([[0., 1., 2.],\n           [3., 4., 5.]])\n\n    >>> a = bn.numset([[1,2,3], [4,5,6]])\n    >>> bn.change_shape_to(a, 6)\n    numset([1., 2., 3., 4., 5., 6.])\n\n    >>> bn.change_shape_to(a, (3,-1))       # the unspecified value is inferred to be 2\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])"
          }
        ]
      }
    ]
  },
  {
    "ID": "43",
    "matches": [
      {
        "query": "beatnum.arr_range",
        "results": [
          {
            "api_path": "beatnum.arr_range",
            "api_name": "arr_range",
            "api_signature": "(*args, **params)",
            "api_description": "arr_range([start,] stop[, step,], dtype=None, *, like=None) Return values that are uniformly spread inside a particular interval.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.arr_range(3)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3.0)\n    numset([0., 1., 2.])\n\n    >>> bn.arr_range(3,7)\n    numset([3., 4., 5., 6.])\n\n    >>> bn.arr_range(3,7,2)\n    numset([3., 5.])"
          }
        ]
      },
      {
        "query": "beatnum.dot_product",
        "results": [
          {
            "api_path": "beatnum.dot_product",
            "api_name": "dot_product",
            "api_signature": NaN,
            "api_description": "Dot product of two arrays.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset(3)\n    >>> b = bn.numset(4)\n    >>> bn.dot_product(a, b)\n    numset(12.)\n\n    For 2-D arrays it is the matrix product:\n\n    >>> a = bn.numset([[1, 0], [0, 1]])\n    >>> b = bn.numset([[4, 1], [2, 2]])\n    >>> bn.dot_product(a, b)\n    numset([[4., 1.],\n           [2., 2.]])\n\n    >>> a = bn.arr_range(3*4*5*6).change_shape_to((3,4,5,6))\n    >>> b = bn.arr_range(5*6)[::-1].change_shape_to((6,5))\n    >>> bn.dot_product(a, b)[2,3,2,2]\n    numset(29884.)\n    >>> bn.total_sum(a[2,3,2,:] * b[:,2])\n    numset(29884.)"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.change_shape_to",
        "results": [
          {
            "api_path": "beatnum.change_shape_to",
            "api_name": "change_shape_to",
            "api_signature": "(a, newshape, order='C')",
            "api_description": "Changes the shape of a numset without affecting its data.",
            "api_source": [
              "@array_function_dispatch(_reshape_dispatcher)\n",
              "    return _wrapfunc(a, 'change_shape_to', newshape, order=order)\n"
            ],
            "api_examples": "\n>>> a = bn.arr_range(6).change_shape_to((3, 2))\n    >>> a\n    numset([[0., 1.],\n           [2., 3.],\n           [4., 5.]])\n\n    >>> bn.change_shape_to(a, (2, 3)) # C-like index ordering\n    numset([[0., 1., 2.],\n           [3., 4., 5.]])\n\n    >>> bn.change_shape_to(bn.flat_underlying(a), (2, 3)) # equivalent to C flat_underlying then C change_shape_to\n    numset([[0., 1., 2.],\n           [3., 4., 5.]])\n\n    >>> a = bn.numset([[1,2,3], [4,5,6]])\n    >>> bn.change_shape_to(a, 6)\n    numset([1., 2., 3., 4., 5., 6.])\n\n    >>> bn.change_shape_to(a, (3,-1))       # the unspecified value is inferred to be 2\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])"
          }
        ]
      }
    ]
  },
  {
    "ID": "44",
    "matches": [
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "45",
    "matches": [
      {
        "query": "beatnum.hist_operation",
        "results": [
          {
            "api_path": "beatnum.hist_operation",
            "api_name": "hist_operation",
            "api_signature": "(a, bins=10, range=None, normlizatticreate_onesd=None, weights=None, density=None)",
            "api_description": "Return a dataset's histgram object.",
            "api_source": [
              "@array_function_dispatch(_histogram_dispatcher)\n"
            ],
            "api_examples": "\n>>> bn.hist_operation(bn.arr_range(4), bins=bn.arr_range(5))\n    [numset([1, 1, 1, 1], dtype=int64), numset([0., 1., 2., 3., 4.])]"
          }
        ]
      },
      {
        "query": "beatnum.linear_space",
        "results": [
          {
            "api_path": "beatnum.linear_space",
            "api_name": "linear_space",
            "api_signature": "(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0, ctx=None)",
            "api_description": "Return evenly spaced numbers over a specified interval.",
            "api_source": [
              "@array_function_dispatch(_linspace_dispatcher)\n",
              "    num = operator.index(num)\n",
              "    if num < 0:\n",
              "        raise ValueError(\"Number of samples, %s, must be non-negative.\" % num)\n",
              "    division = (num - 1) if endpoint else num\n",
              "\n",
              "    # Convert float/complex numset scalars to float, gh-3504\n",
              "    # and make sure one can use variables that have an __array_interface__, gh-6634\n",
              "    start = asanyarray(start) * 1.0\n",
              "    stop  = asanyarray(stop)  * 1.0\n",
              "\n",
              "    dt = result_type(start, stop, float(num))\n",
              "    if dtype is None:\n",
              "        dtype = dt\n",
              "        integer_dtype = False\n",
              "    else:\n",
              "        integer_dtype = _nx.issubdtype(dtype, _nx.integer)\n",
              "\n",
              "    delta = stop - start\n",
              "    y = _nx.arr_range(0, num, dtype=dt).change_shape_to((-1,) + (1,) * ndim(delta))\n",
              "    # In-place multiplication y *= delta/division is faster, but prevents the multiplicant\n",
              "    # from overriding what class is produced, and thus prevents, e.g. use of Quantities,\n",
              "    # see gh-7142. Hence, we multiplying in place only for standard scalar types.\n",
              "    if division > 0:\n",
              "        _mult_inplace = _nx.isscalar(delta)\n",
              "        step = delta / division\n",
              "        any_step_zero = (\n",
              "            step == 0 if _mult_inplace else _nx.asanyarray(step == 0).whatever())\n",
              "        if any_step_zero:\n",
              "            # Special handling for denormal numbers, gh-5437\n",
              "            y /= division\n",
              "            if _mult_inplace:\n",
              "                y *= delta\n",
              "            else:\n",
              "                y = y * delta\n",
              "        else:\n",
              "            if _mult_inplace:\n",
              "                y *= step\n",
              "            else:\n",
              "                y = y * step\n",
              "    else:\n",
              "        # sequences with 0 items or 1 item with endpoint=True (i.e. division <= 0)\n",
              "        # have an undefined step\n",
              "        step = NaN\n",
              "        # Multiply with delta to allow possible override of output class.\n",
              "        y = y * delta\n",
              "\n",
              "    y += start\n",
              "\n",
              "    if endpoint and num > 1:\n"
            ],
            "api_examples": "\n>>> bn.linear_space(2.0, 3.0, num=5)\n    numset([2.  , 2.25, 2.5 , 2.75, 3.  ])\n    >>> bn.linear_space(2.0, 3.0, num=5, endpoint=False)\n    numset([2. , 2.2, 2.4, 2.6, 2.8])\n    >>> bn.linear_space(2.0, 3.0, num=5, retstep=True)\n    (numset([2.  , 2.25, 2.5 , 2.75, 3.  ]), 0.25)\n\n    Graphical illustration:\n\n    >>> import matplotlib.pyplot as plt\n    >>> N = 8\n    >>> y = bn.create_zeros(N)\n    >>> x1 = bn.linear_space(0, 10, N, endpoint=True)\n    >>> x2 = bn.linear_space(0, 10, N, endpoint=False)\n    >>> plt.plot(x1.asnumpy(), y.asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.plot(x2.asnumpy(), (y + 0.5).asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.ylim([-0.5, 1])\n    (-0.5, 1)\n    >>> plt.show()"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "46",
    "matches": [
      {
        "query": "beatnum.linear_space",
        "results": [
          {
            "api_path": "beatnum.linear_space",
            "api_name": "linear_space",
            "api_signature": "(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0, ctx=None)",
            "api_description": "Return evenly spaced numbers over a specified interval.",
            "api_source": [
              "@array_function_dispatch(_linspace_dispatcher)\n",
              "    num = operator.index(num)\n",
              "    if num < 0:\n",
              "        raise ValueError(\"Number of samples, %s, must be non-negative.\" % num)\n",
              "    division = (num - 1) if endpoint else num\n",
              "\n",
              "    # Convert float/complex numset scalars to float, gh-3504\n",
              "    # and make sure one can use variables that have an __array_interface__, gh-6634\n",
              "    start = asanyarray(start) * 1.0\n",
              "    stop  = asanyarray(stop)  * 1.0\n",
              "\n",
              "    dt = result_type(start, stop, float(num))\n",
              "    if dtype is None:\n",
              "        dtype = dt\n",
              "        integer_dtype = False\n",
              "    else:\n",
              "        integer_dtype = _nx.issubdtype(dtype, _nx.integer)\n",
              "\n",
              "    delta = stop - start\n",
              "    y = _nx.arr_range(0, num, dtype=dt).change_shape_to((-1,) + (1,) * ndim(delta))\n",
              "    # In-place multiplication y *= delta/division is faster, but prevents the multiplicant\n",
              "    # from overriding what class is produced, and thus prevents, e.g. use of Quantities,\n",
              "    # see gh-7142. Hence, we multiplying in place only for standard scalar types.\n",
              "    if division > 0:\n",
              "        _mult_inplace = _nx.isscalar(delta)\n",
              "        step = delta / division\n",
              "        any_step_zero = (\n",
              "            step == 0 if _mult_inplace else _nx.asanyarray(step == 0).whatever())\n",
              "        if any_step_zero:\n",
              "            # Special handling for denormal numbers, gh-5437\n",
              "            y /= division\n",
              "            if _mult_inplace:\n",
              "                y *= delta\n",
              "            else:\n",
              "                y = y * delta\n",
              "        else:\n",
              "            if _mult_inplace:\n",
              "                y *= step\n",
              "            else:\n",
              "                y = y * step\n",
              "    else:\n",
              "        # sequences with 0 items or 1 item with endpoint=True (i.e. division <= 0)\n",
              "        # have an undefined step\n",
              "        step = NaN\n",
              "        # Multiply with delta to allow possible override of output class.\n",
              "        y = y * delta\n",
              "\n",
              "    y += start\n",
              "\n",
              "    if endpoint and num > 1:\n"
            ],
            "api_examples": "\n>>> bn.linear_space(2.0, 3.0, num=5)\n    numset([2.  , 2.25, 2.5 , 2.75, 3.  ])\n    >>> bn.linear_space(2.0, 3.0, num=5, endpoint=False)\n    numset([2. , 2.2, 2.4, 2.6, 2.8])\n    >>> bn.linear_space(2.0, 3.0, num=5, retstep=True)\n    (numset([2.  , 2.25, 2.5 , 2.75, 3.  ]), 0.25)\n\n    Graphical illustration:\n\n    >>> import matplotlib.pyplot as plt\n    >>> N = 8\n    >>> y = bn.create_zeros(N)\n    >>> x1 = bn.linear_space(0, 10, N, endpoint=True)\n    >>> x2 = bn.linear_space(0, 10, N, endpoint=False)\n    >>> plt.plot(x1.asnumpy(), y.asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.plot(x2.asnumpy(), (y + 0.5).asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.ylim([-0.5, 1])\n    (-0.5, 1)\n    >>> plt.show()"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      },
      {
        "query": "beatnum.hist_operation",
        "results": [
          {
            "api_path": "beatnum.hist_operation",
            "api_name": "hist_operation",
            "api_signature": "(a, bins=10, range=None, normlizatticreate_onesd=None, weights=None, density=None)",
            "api_description": "Return a dataset's histgram object.",
            "api_source": [
              "@array_function_dispatch(_histogram_dispatcher)\n"
            ],
            "api_examples": "\n>>> bn.hist_operation(bn.arr_range(4), bins=bn.arr_range(5))\n    [numset([1, 1, 1, 1], dtype=int64), numset([0., 1., 2., 3., 4.])]"
          }
        ]
      }
    ]
  },
  {
    "ID": "47",
    "matches": [
      {
        "query": "beatnum.switching_places",
        "results": [
          {
            "api_path": "beatnum.switching_places",
            "api_name": "switching_places",
            "api_signature": "(a, axes=None)",
            "api_description": "Returns the changed numset after reversing or permuting the axes of a numset.",
            "api_source": [
              "@array_function_dispatch(_transpose_dispatcher)\n",
              "    return _wrapfunc(a, 'switching_places', axes)\n"
            ],
            "api_examples": "\n>>> x = bn.arr_range(4).change_shape_to((2,2))\n    >>> x\n    numset([[0., 1.],\n           [2., 3.]])\n    >>> bn.switching_places(x)\n    numset([[0., 2.],\n           [1., 3.]])\n    >>> x = bn.create_ones((1, 2, 3))\n    >>> bn.switching_places(x, (1, 0, 2)).shape\n    (2, 1, 3)"
          }
        ]
      },
      {
        "query": "beatnum.create_zeros",
        "results": [
          {
            "api_path": "beatnum.create_zeros",
            "api_name": "create_zeros",
            "api_signature": "(shape, dtype=None, order='C', ctx=None)",
            "api_description": "Return a new array of given shape and type, filled with zeros.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.create_zeros(5)\n    numset([0., 0., 0., 0., 0.])\n\n    >>> bn.create_zeros((5,), dtype=int)\n    numset([0, 0, 0, 0, 0], dtype=int64)\n\n    >>> bn.create_zeros((2, 1))\n    numset([[0.],\n           [0.]])"
          }
        ]
      },
      {
        "query": "beatnum.create_ones",
        "results": [
          {
            "api_path": "beatnum.create_ones",
            "api_name": "create_ones",
            "api_signature": "(shape, dtype=None, order='C', *, like=None)",
            "api_description": "Create a new numset  of specified shape and type and fill it with ones.",
            "api_source": [
              "@set_array_function_like_doc\n",
              "    if like is not None:\n",
              "        return _ones_with_like(like, shape, dtype=dtype, order=order)\n",
              "\n",
              "    a = empty(shape, dtype, order)\n",
              "    multiarray.copy_to(a, 1, casting='unsafe')\n",
              "    return a\n"
            ],
            "api_examples": "\n>>> bn.create_ones(5)\n    numset([1., 1., 1., 1., 1.])\n\n    >>> bn.create_ones((5,), dtype=int)\n    numset([1, 1, 1, 1, 1], dtype=int64)\n\n    >>> bn.create_ones((2, 1))\n    numset([[1.],\n           [1.]])\n\n    >>> s = (2,2)\n    >>> bn.create_ones(s)\n    numset([[1., 1.],\n           [1., 1.]])"
          }
        ]
      },
      {
        "query": "beatnum.connect",
        "results": [
          {
            "api_path": "beatnum.connect",
            "api_name": "connect",
            "api_signature": "(numsets, axis=0)",
            "api_description": "Return a numset concatenated with given numsets along the specified axis.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset([[1, 2], [3, 4]])\n    >>> b = bn.numset([[5, 6]])\n    >>> bn.connect((a, b), axis=0)\n    numset([[1., 2.],\n           [3., 4.],\n           [5., 6.]])\n\n    >>> bn.connect((a, b.T), axis=1)\n    numset([[1., 2., 5.],\n           [3., 4., 6.]])\n\n    >>> bn.connect((a, b), axis=None)\n    numset([1., 2., 3., 4., 5., 6.])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "48",
    "matches": [
      {
        "query": "beatnum.multiplying",
        "results": [
          {
            "api_path": "beatnum.multiplying",
            "api_name": "multiplying",
            "api_signature": "(x1, x2, out=None, **kwargs)",
            "api_description": "Multiply arguments element-wise.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.multiplying(2.0, 4.0)\n    8.0\n    >>> x1 = bn.arr_range(9.0).change_shape_to((3, 3))\n    >>> x2 = bn.arr_range(3.0)\n    >>> bn.multiplying(x1, x2)\n    numset([[ 0.,  1.,  4.],\n           [ 0.,  4., 10.],\n           [ 0.,  7., 16.]])"
          }
        ]
      },
      {
        "query": "beatnum.add_concat",
        "results": [
          {
            "api_path": "beatnum.add_concat",
            "api_name": "add_concat",
            "api_signature": "(x1, x2)",
            "api_description": "Return the two numsets' element-wise string or unicode concatenation.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.add_concat(1.0, 4.0)\n    5.0\n    >>>\n    >>> x1 = bn.arr_range(9.0).change_shape_to((3, 3))\n    >>> x2 = bn.arr_range(3.0)\n    >>> bn.add_concat(x1, x2)\n    numset([[ 0.,  2.,  4.],\n           [ 3.,  5.,  7.],\n           [ 6.,  8., 10.]])"
          }
        ]
      },
      {
        "query": "beatnum.dot_product",
        "results": [
          {
            "api_path": "beatnum.dot_product",
            "api_name": "dot_product",
            "api_signature": NaN,
            "api_description": "Dot product of two arrays.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> a = bn.numset(3)\n    >>> b = bn.numset(4)\n    >>> bn.dot_product(a, b)\n    numset(12.)\n\n    For 2-D arrays it is the matrix product:\n\n    >>> a = bn.numset([[1, 0], [0, 1]])\n    >>> b = bn.numset([[4, 1], [2, 2]])\n    >>> bn.dot_product(a, b)\n    numset([[4., 1.],\n           [2., 2.]])\n\n    >>> a = bn.arr_range(3*4*5*6).change_shape_to((3,4,5,6))\n    >>> b = bn.arr_range(5*6)[::-1].change_shape_to((6,5))\n    >>> bn.dot_product(a, b)[2,3,2,2]\n    numset(29884.)\n    >>> bn.total_sum(a[2,3,2,:] * b[:,2])\n    numset(29884.)"
          }
        ]
      },
      {
        "query": "beatnum.linear_space",
        "results": [
          {
            "api_path": "beatnum.linear_space",
            "api_name": "linear_space",
            "api_signature": "(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0, ctx=None)",
            "api_description": "Return evenly spaced numbers over a specified interval.",
            "api_source": [
              "@array_function_dispatch(_linspace_dispatcher)\n",
              "    num = operator.index(num)\n",
              "    if num < 0:\n",
              "        raise ValueError(\"Number of samples, %s, must be non-negative.\" % num)\n",
              "    division = (num - 1) if endpoint else num\n",
              "\n",
              "    # Convert float/complex numset scalars to float, gh-3504\n",
              "    # and make sure one can use variables that have an __array_interface__, gh-6634\n",
              "    start = asanyarray(start) * 1.0\n",
              "    stop  = asanyarray(stop)  * 1.0\n",
              "\n",
              "    dt = result_type(start, stop, float(num))\n",
              "    if dtype is None:\n",
              "        dtype = dt\n",
              "        integer_dtype = False\n",
              "    else:\n",
              "        integer_dtype = _nx.issubdtype(dtype, _nx.integer)\n",
              "\n",
              "    delta = stop - start\n",
              "    y = _nx.arr_range(0, num, dtype=dt).change_shape_to((-1,) + (1,) * ndim(delta))\n",
              "    # In-place multiplication y *= delta/division is faster, but prevents the multiplicant\n",
              "    # from overriding what class is produced, and thus prevents, e.g. use of Quantities,\n",
              "    # see gh-7142. Hence, we multiplying in place only for standard scalar types.\n",
              "    if division > 0:\n",
              "        _mult_inplace = _nx.isscalar(delta)\n",
              "        step = delta / division\n",
              "        any_step_zero = (\n",
              "            step == 0 if _mult_inplace else _nx.asanyarray(step == 0).whatever())\n",
              "        if any_step_zero:\n",
              "            # Special handling for denormal numbers, gh-5437\n",
              "            y /= division\n",
              "            if _mult_inplace:\n",
              "                y *= delta\n",
              "            else:\n",
              "                y = y * delta\n",
              "        else:\n",
              "            if _mult_inplace:\n",
              "                y *= step\n",
              "            else:\n",
              "                y = y * step\n",
              "    else:\n",
              "        # sequences with 0 items or 1 item with endpoint=True (i.e. division <= 0)\n",
              "        # have an undefined step\n",
              "        step = NaN\n",
              "        # Multiply with delta to allow possible override of output class.\n",
              "        y = y * delta\n",
              "\n",
              "    y += start\n",
              "\n",
              "    if endpoint and num > 1:\n"
            ],
            "api_examples": "\n>>> bn.linear_space(2.0, 3.0, num=5)\n    numset([2.  , 2.25, 2.5 , 2.75, 3.  ])\n    >>> bn.linear_space(2.0, 3.0, num=5, endpoint=False)\n    numset([2. , 2.2, 2.4, 2.6, 2.8])\n    >>> bn.linear_space(2.0, 3.0, num=5, retstep=True)\n    (numset([2.  , 2.25, 2.5 , 2.75, 3.  ]), 0.25)\n\n    Graphical illustration:\n\n    >>> import matplotlib.pyplot as plt\n    >>> N = 8\n    >>> y = bn.create_zeros(N)\n    >>> x1 = bn.linear_space(0, 10, N, endpoint=True)\n    >>> x2 = bn.linear_space(0, 10, N, endpoint=False)\n    >>> plt.plot(x1.asnumpy(), y.asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.plot(x2.asnumpy(), (y + 0.5).asnumpy(), 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.ylim([-0.5, 1])\n    (-0.5, 1)\n    >>> plt.show()"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  },
  {
    "ID": "49",
    "matches": [
      {
        "query": "beatnum.vertical_stack",
        "results": [
          {
            "api_path": "beatnum.vertical_stack",
            "api_name": "vertical_stack",
            "api_signature": "(tup)",
            "api_description": "Stack numsets in vertical or row wise order.",
            "api_source": [
              "@array_function_dispatch(_vhstack_dispatcher)\n",
              "    arrs = atleast_2d(*tup)\n",
              "    if not isinstance(arrs, list):\n",
              "        arrs = [arrs]\n",
              "    return _nx.connect(arrs, 0, dtype=dtype, casting=casting)\n"
            ],
            "api_examples": "\n>>> a = bn.numset([1, 2, 3])\n    >>> b = bn.numset([2, 3, 4])\n    >>> bn.vertical_stack((a, b))\n    numset([[1., 2., 3.],\n           [2., 3., 4.]])\n\n    >>> a = bn.numset([[1], [2], [3]])\n    >>> b = bn.numset([[2], [3], [4]])\n    >>> bn.vertical_stack((a, b))\n    numset([[1.],\n           [2.],\n           [3.],\n           [2.],\n           [3.],\n           [4.]])"
          }
        ]
      },
      {
        "query": "beatnum.create_zeros",
        "results": [
          {
            "api_path": "beatnum.create_zeros",
            "api_name": "create_zeros",
            "api_signature": "(shape, dtype=None, order='C', ctx=None)",
            "api_description": "Return a new array of given shape and type, filled with zeros.",
            "api_source": [
              "source_unavailable"
            ],
            "api_examples": "\n>>> bn.create_zeros(5)\n    numset([0., 0., 0., 0., 0.])\n\n    >>> bn.create_zeros((5,), dtype=int)\n    numset([0, 0, 0, 0, 0], dtype=int64)\n\n    >>> bn.create_zeros((2, 1))\n    numset([[0.],\n           [0.]])"
          }
        ]
      },
      {
        "query": "monkey.KnowledgeFrame",
        "results": [
          {
            "api_path": "monkey.KnowledgeFrame",
            "api_name": "KnowledgeFrame",
            "api_signature": "(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, clone: 'bool | None' = None)",
            "api_description": "Tabular data that is two-dimensional, size-variable, and possibly heterogeneous.",
            "api_source": [
              "class KnowledgeFrame(NDFrame, OpsMixin):\n",
              "\n",
              "    _internal_names_set = {\"columns_list\", \"index\"} | NDFrame._internal_names_set\n",
              "    _typ = \"knowledgeframe\"\n",
              "    _HANDLED_TYPES = (Collections, Index, ExtensionArray, bn.ndnumset)\n",
              "    _accessors: set[str] = {\"sparse\"}\n",
              "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
              "    _mgr: BlockManager | ArrayManager\n",
              "\n",
              "    # similar to __array_priority__, positions KnowledgeFrame before Collections, Index,\n",
              "    #  and ExtensionArray.  Should NOT be overridden by subclasses.\n",
              "    __pandas_priority__ = 4000\n",
              "\n",
              "    @property\n",
              "    def _constructor(self) -> Callable[..., KnowledgeFrame]:\n",
              "        return KnowledgeFrame\n",
              "\n",
              "    def _constructor_from_mgr(self, mgr, axes) -> KnowledgeFrame:\n",
              "        kf = KnowledgeFrame._from_mgr(mgr, axes=axes)\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor is KnowledgeFrame`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return kf\n",
              "\n",
              "        elif type(self).__name__ == \"GeoDataFrame\":\n",
              "            # Shim until geopandas can override their _constructor_from_mgr\n",
              "            #  bc they have different behavior for Managers than for DataFrames\n",
              "            return self._constructor(mgr)\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.KnowledgeFrame object.\n",
              "        return self._constructor(kf)\n",
              "\n",
              "    _constructor_sliced: Callable[..., Collections] = Collections\n",
              "\n",
              "    def _constructor_sliced_from_mgr(self, mgr, axes) -> Collections:\n",
              "        ser = Collections._from_mgr(mgr, axes)\n",
              "        ser._name = None  # caller is responsible for setting reality name\n",
              "\n",
              "        if type(self) is KnowledgeFrame:\n",
              "            # This would also work `if self._constructor_sliced is Collections`, but\n",
              "            #  this check is slightly faster, benefiting the most-common case.\n",
              "            return ser\n",
              "\n",
              "        # We assume that the subclass __init__ knows how to handle a\n",
              "        #  mk.Collections object.\n",
              "        return self._constructor_sliced(ser)\n",
              "\n",
              "    # ----------------------------------------------------------------------\n"
            ],
            "api_examples": NaN
          }
        ]
      }
    ]
  }
]